{"meta":{"title":"aLong","subtitle":"一个人总是可以善待他毫不在意的人。--王尔德","description":null,"author":"aLong","url":"http://blog.51ai.vip","root":"/"},"pages":[{"title":"关于","date":"2019-03-29T04:30:18.000Z","updated":"2020-04-14T06:55:05.124Z","comments":true,"path":"about/index.html","permalink":"http://blog.51ai.vip/about/index.html","excerpt":"","text":"站点 小站记录信息，写写笔记。之前wordpress搭建的博客意外被黑。数据好在有备份，之后又经历vps被卖家停止，原因是他们不做这生意，他们上级把他们的客户封停了….。 2014年-2018年数据丢失,部分数据有备份,自己太懒了. 后来想想算了，放在GitHub上吧。 个人信息 Name: aLong QQ：604302709 Email：604302709@qq.com"},{"title":"分类","date":"2021-01-22T05:20:37.918Z","updated":"2020-04-14T06:55:05.125Z","comments":true,"path":"categories/index.html","permalink":"http://blog.51ai.vip/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-01-22T05:20:37.917Z","updated":"2020-04-14T06:55:05.125Z","comments":true,"path":"tags/index.html","permalink":"http://blog.51ai.vip/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"新年新体验hugo","slug":"新年新体验hugo","date":"2022-02-17T03:29:23.000Z","updated":"2022-02-17T03:35:59.500Z","comments":true,"path":"2022/02/17/新年新体验hugo/","link":"","permalink":"http://blog.51ai.vip/2022/02/17/新年新体验hugo/","excerpt":"","text":"新年体验hugo从hexo到hugo之前一直用hexo。觉得还可以，整体没什么问题。偶尔出问题基本上是node版本的问题。nvm必不可少啊。之前一直想试试hugo，一直懒得搞。 今年想试试hugo，目前已经吧文章copy过去。然后简单改下tags。目前已经发不到gitPages上。地址： aLong blog","categories":[{"name":"hugo","slug":"hugo","permalink":"http://blog.51ai.vip/categories/hugo/"}],"tags":[{"name":"hugo","slug":"hugo","permalink":"http://blog.51ai.vip/tags/hugo/"}]},{"title":"Zabbix6 网络发现","slug":"Zabbix-网络发现","date":"2022-01-14T02:15:53.000Z","updated":"2022-05-30T09:33:53.345Z","comments":true,"path":"2022/01/14/Zabbix-网络发现/","link":"","permalink":"http://blog.51ai.vip/2022/01/14/Zabbix-网络发现/","excerpt":"","text":"Zabbix6 网络发现 功能 快速发现并添加主机 简单的管理 随着环境的改变而快速搭建系统 发现配置依据 IP地址段 基于服务(FTP、SSH、Web、POP3、IMAP、TCP…)的 从Zabbix-Agent接收到的信息 SNMP agent接收的信息 添加方式 创建 Discovery rule Name：规则名称（唯一） Discovery by proxy： 是否由代理执行 IP range： IP地址范围 单个IP: 192.168.1.33IP段: 192.168.1-10.1-255. 范围受限于覆盖地址的总数（小于64K）。子网掩码: : 192.168.4.0/24支持的子网掩码:/16 - /30 for IPv4 addresses/112 - /128 for IPv6 addresses\\IP列表: 192.168.1.1-255, 192.168.2.1-100, 192.168.2.200, 192.168.4.0/24Zabbix 3.0.0起，此字段支持空格，表格和多行。 Update interval: Zabbix执行规则的频率 Checks: 发现的方式 Device uniqueness criteria：设备唯一标识 Host name ： 主机名 Visible name：描述名 这三个选项是根据，checks里面的相关类型出来的数据。基本上都有IP地址，当checks Type 选择了 SNMP或者zabbix agent时，下面选项可以提供这两种对应的数据作为选项。 唯一标识可以通过IP(默认)，或者SNMP的取值，或者zabbix agent取值。重复的名称不会处理。 Host name 和 Visible name选项类似。Host name肯定是要唯一的。 创建 Discovery actions action配置： Name ： action 名称 Conditions：action的条件 Enabled: action的开关 条件详情： Type多个方式： 可以通过多种类型适配条件。 根据选择的Type类型，下面的Operator是根据Type来配置的选项。 Operator： 基本就是 等于或不等于。 第三个选项是动态的，当选择 Type 是Discovery check，下面是配置 Discovery check的名称。 如果Type 是Host IP，那么第三个选项就变成了Value。 配置Operations： 配置这个Operations 的意思是，当通过前面action条件匹配的到数据后续的操作内容。例如加入/移除设备组、关联/取消模版、发送通知等操作。 验证结果我上面截图的例子中： actions 配置的内容为，通过icmp ping 发现负责此条件的设备，把这些设备分配到xxx网络摄像头的设备组里；并把主机关联的模版是icmp ping。 发现之后的结果就是： 在内网找到很多摄像头","categories":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://blog.51ai.vip/categories/Zabbix/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.51ai.vip/tags/zabbix/"}]},{"title":"linux环境redis开机启动","slug":"linux环境redis开机启动","date":"2022-01-11T02:16:39.000Z","updated":"2022-01-11T05:12:25.611Z","comments":true,"path":"2022/01/11/linux环境redis开机启动/","link":"","permalink":"http://blog.51ai.vip/2022/01/11/linux环境redis开机启动/","excerpt":"","text":"前提系统部署在ubuntu20.04中，用到redis数据库。但是测试时候，设备重启发现redis服务没有启动。由于是变异安装的，系统找不到redis.service。 解决方案系统添加服务文件，并执行。 编写文件文件路径/usr/lib/systemd/system 编写文件 vi /usr/lib/systemd/system/redis.service [Unit] #服务描述 Description=Redis persistent key-value database #服务依赖 After=network.target After=network-online.target Wants=network-online.target [Service] #启动 命令 ExecStart=/home/monitor/redis-6.0.8/src/redis-server /home/monitor/redis-6.0.8/redis.conf --protected-mode no #停止命令 ExecStop=/home/monitor/redis-6.0.8/src/redis-cli shutdown # Restart=always #服务类型 Type=forking #User=redis #Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] #服务安装设置 WantedBy=multi-user.target 服务配置文件分为[Unit]、[Service]和[Install]三部分。具体详细的解释需要结合linux知识补充。 服务生效系统重新读取所有服务文件： systemctl daemon-reload启用/禁用开机自启动: systemctl enable/disable redis启动/重启redis： systemctl start/restart redis","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://blog.51ai.vip/tags/Redis/"}]},{"title":"armbian配置（N1盒子）","slug":"armbian系统(斐讯N1盒子)相关配置","date":"2021-11-20T06:04:47.000Z","updated":"2022-01-10T09:23:56.662Z","comments":true,"path":"2021/11/20/armbian系统(斐讯N1盒子)相关配置/","link":"","permalink":"http://blog.51ai.vip/2021/11/20/armbian系统(斐讯N1盒子)相关配置/","excerpt":"","text":"armbian配置（N1盒子） 设置时区：timedatectl set-timezone Asia/Shanghai 安装docker apt update apt install ca-certificates curl gnupg lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | tee /etc/apt/sources.list.d/docker.list &gt; /dev/null apt update apt install docker-ce docker-ce-cli containerd.io 安装docker-composewget地址是加速器转换地址，版本和地址请根据版本号编辑地址 wget https://download.fastgit.org/docker/compose/releases/download/v2.1.1/docker-compose-linux-aarch64 &amp;&amp; mv docker-compose-linux-aarch64 /usr/local/bin/docker-compose &amp;&amp; chmod +x /usr/local/bin/docker-compose WIFI 查看附近无线网络信号：nmcli dev wifi list 无密码的 WIFI：nmcli device wifi connect &lt;SSID|BSSID&gt; 加密WIFI： nmcli device wifi connect &lt;SSID|BSSID&gt; password 网卡配置 设置多IP 1234auto eth0:1allow-hotplug eth0:1iface eth0:1 inet staticaddress 1.1.1.1/30","categories":[{"name":"NetWork","slug":"NetWork","permalink":"http://blog.51ai.vip/categories/NetWork/"}],"tags":[{"name":"NetWork","slug":"NetWork","permalink":"http://blog.51ai.vip/tags/NetWork/"}]},{"title":"S5720 SNMP v3配置","slug":"S5720 SNMP v3","date":"2021-11-16T08:38:35.000Z","updated":"2022-01-10T09:22:53.120Z","comments":true,"path":"2021/11/16/S5720 SNMP v3/","link":"","permalink":"http://blog.51ai.vip/2021/11/16/S5720 SNMP v3/","excerpt":"","text":"S5720 SNMP v3配置系统视图system-view SNMP服务snmp-agent 管理端口(默认161)snmp-agent udp-port *port-num* 配置版本(默认v3)snmp-agent sys-info version *v3* 配置用户组snmp-agent group v3 *group-name* {authentication | privacy | noauthentication} 三种认证加密方式 配置v3用户snmp-agent usm-user v3 *user-name* [ group *group-name*] 配置用户认证密码snmp-agent usm-user v3 *user-name* authentication-mode { md5 | sha } [ cipher *password* ] 配置加密密码snmp-agent usm-user v3 *user-name* privacy-mode { des56 | aes128 |aes192 | aes256 | 3des } [ cipher *password* ]","categories":[{"name":"NetWork","slug":"NetWork","permalink":"http://blog.51ai.vip/categories/NetWork/"},{"name":"SNMP","slug":"NetWork/SNMP","permalink":"http://blog.51ai.vip/categories/NetWork/SNMP/"}],"tags":[{"name":"NetWork","slug":"NetWork","permalink":"http://blog.51ai.vip/tags/NetWork/"}]},{"title":"zabbix proxy cannot perform check now for itemid [xxxxx]: item is not in cache","slug":"zabbix-proxy-cannot-perform-check-now-for-itemid-xxxxx-item-is-not-in-cache","date":"2021-10-27T07:06:44.000Z","updated":"2022-05-30T09:30:21.689Z","comments":true,"path":"2021/10/27/zabbix-proxy-cannot-perform-check-now-for-itemid-xxxxx-item-is-not-in-cache/","link":"","permalink":"http://blog.51ai.vip/2021/10/27/zabbix-proxy-cannot-perform-check-now-for-itemid-xxxxx-item-is-not-in-cache/","excerpt":"","text":"zabbix proxy cannot perform check now for itemid [xxxxx]: item is not in cache情况接上次做完容器部署proxy后，为其添加host进行添加任务。 发现一直没有数据，就到item里面执行 execute now。 然后过了几分钟回来一看，还是没有。 Emmm，看下log吧。 Server没一场，那问题就在proxy了吧。 连上proxy去看看： 提示好像是去检查对应的itemid，然后说item不在还cache中。赶紧上网科普！ 原因 因为是主动的proxy，那他会定期去server要数据。 这个3600就是配置的更新周期了。1个小时才去要一次，所以肯定是没监控了。 为了验证，就等了1小时看看：实锤了，1小时。后面也就有了数据。Host是1小时之后开始有数据的，也就是他同步后就开始执行监控项了。 查询到的内容： [地址](https://subscription.packtpub.com/book/networking_and_servers/9781784399764/1/ch01lvl1sec10/understanding-the-zabbix-proxies-data-flow) 解决Ok，那么在重新部署的容器加上此参数(ZBX_CONFIGFREQUENCY)。 12345678910111213docker run --name zbxproxy -d \\-e ZBX_SERVER_HOST=192.168.10.66 \\-e ZBX_HOSTNAME=\"testproxy\" \\-e ZBX_TIMEOUT=\"10\" \\-e ZBX_TLSACCEPT=psk \\-e ZBX_TLSCONNECT=psk \\-e ZBX_TLSPSKIDENTITY=helloworld \\-e ZBX_TLSPSKFILE=zbx_proxy.psk \\-e ZBX_CONFIGFREQUENCY=600 \\-v /etc/localtime:/etc/localtime:ro \\-v /zbx_proxy.psk:/var/lib/zabbix/enc/zbx_proxy.psk \\--restart=always \\zabbix/zabbix-proxy-sqlite3:alpine-trunk –祝好 本文结束","categories":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://blog.51ai.vip/categories/Zabbix/"}],"tags":[]},{"title":"Zabbix-Proxy 部署&运行","slug":"Zabbix-Proxy-部署-运行","date":"2021-06-24T09:20:40.000Z","updated":"2022-01-17T06:48:20.776Z","comments":true,"path":"2021/06/24/Zabbix-Proxy-部署-运行/","link":"","permalink":"http://blog.51ai.vip/2021/06/24/Zabbix-Proxy-部署-运行/","excerpt":"","text":"前提版本： zabbix-server 5.4 任务： 通过SNMP监控网络设备，需要需通过zabbix-proxy 发送到zabbix-server。 安装Zabbix-Proxy 安装Zabbix仓库 12345wget https://repo.zabbix.com/zabbix/5.4/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.4-1+ubuntu20.04_all.debdpkg -i zabbix-release_5.4-1+ubuntu20.04_all.debapt update 安装Zabbix-proxy &amp; mysql 这里我选择的是mysql作为数据库 apt install mysql-server apt install zabbix-proxy-mysql 导入数据 zcat /usr/share/doc/zabbix-proxy-mysql/schema.sql.gz | mysql -uzabbix -p zabbix 这里可能跑不通。我装了两次都发现没有 schema.sql.gz 这个文件。如果你也是，那需要找一下这个sql文件。 下载5.4源码包：wget https://cdn.zabbix.com/zabbix/sources/stable/5.4/zabbix-5.4.1.tar.gz解压之后，在 /zabbix-5.4.1/databases/mysql/ 中 通过 cat schema.sql | mysql -uzabbix -p 导入到数据库中。 4.配置zabbix-proxy vim /etc/zabbix/zabbix_proxy.conf 修改Zabbix Server地址,Hostname，在server添加中，此名称要与这里一致。 修改为正确的数据库名字、用户名、密码。 其他配置可以酌情配置。例如server配置频率，log位置，本地缓存时间、主动被动、监听端口等等。 启动zabbix-proxysystemctl start zabbix-proxy &amp;&amp; systemctl enable zabbix-proxy 在zabbix-server 中添加proxy，然后在对应的host主机上选择proxy。 zabbix-proxy log默认配置的位置： /var/log/zabbix/zabbix_proxy.log 祝好！本文结束。","categories":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://blog.51ai.vip/categories/Zabbix/"}],"tags":[{"name":"Monitor","slug":"Monitor","permalink":"http://blog.51ai.vip/tags/Monitor/"}]},{"title":"小米手环解锁MacOS系统笔记本MacBookPro","slug":"小米手环解锁MacBookPro笔记本","date":"2021-05-21T08:51:23.000Z","updated":"2021-07-20T09:46:30.462Z","comments":true,"path":"2021/05/21/小米手环解锁MacBookPro笔记本/","link":"","permalink":"http://blog.51ai.vip/2021/05/21/小米手环解锁MacBookPro笔记本/","excerpt":"","text":"通过小米手环解锁笔记本官方windows是提供了方法的。我目前用的MacBookPro，所以说下苹果笔记本的解锁方式。 安装软件BLEUnlock库 安装方式：brew 安装 brew install bleunlock 或下载程序 下载发布的程序 安装好打开软件： 设备列表选择手环，如果发现不到就在小米运动app中打开实验室选项里小米笔记本解锁开关。 设备列表选择你的小米手环。 解锁RSSI与锁定RSSI 是根据你dBM值来判断是否锁定/解锁笔记本。是一个阈值。 延迟锁定，无信号超时是时间阈值。功能顾名思义。 我这里选择开启了屏保来锁定、以及开机启动。 通过以上配置之后，我们就可以通过小米手环来解锁MacOS笔记本了。 请注意一点如果你是每天背着本上下班的话，那我建议上下班前后别开启此功能。为什么呢，因为你设定的RSSI值肯定是离近笔记本的。这时候你带着手环和笔记本的时候。他很容易就吧本解锁了。然后你发现从书包拿出来本巨热无比。 为啥呢，他唤醒了设备啊 还解锁了～ 这点我不知道怎么搞定呢，好 结束～ 祝好 拜拜～","categories":[{"name":"小米手环","slug":"小米手环","permalink":"http://blog.51ai.vip/categories/小米手环/"}],"tags":[]},{"title":"小米手环表盘自定义","slug":"小米手环变盘自定义","date":"2021-05-20T08:34:55.000Z","updated":"2021-05-20T09:59:29.381Z","comments":true,"path":"2021/05/20/小米手环变盘自定义/","link":"","permalink":"http://blog.51ai.vip/2021/05/20/小米手环变盘自定义/","excerpt":"","text":"前阵子媳妇给买了个手环。小米手环5NFC，价格还可以。 定义表盘手环就不做评价了，我感觉续航不错。屏幕划痕太容了吧。 吐槽完了说下能玩的也就表盘了吧。 出小米运动能同步的那些之外，总想搞点与众不同的。 请访问-&gt;AW 不仅是小米5，6都有了。 我们根据自己的设备来选择。 可以看到有面上方有个分类，语言筛选。 这个还是很有用的，如果你只希望看到中文表盘，那就选择中文。但是中文可能相对较少，我建议所有，然后看喜欢的界面吧。毕竟表盘上也没几个字。 当我们点中某一个表盘，他会进到详情页。 点击下载，可以弹出来具体的表盘文件。 可以看到不同的文件有一些描述，比如语言，以及其他的一些描述。根据喜好下载。 我建议手机下载，省的再从电脑发到手机上。 下完之后，下面就需要同步表盘了。 我目前知道的方式，就是通过一些APP来同步。其他方式我没研究过。 我使用的手机是Iphone，所以我安装此软件：amaztools。 安装完软件进入：主页同步信息等这些不重要略过。 这里app也提供了一些表盘。相比之下，这里面内容不多。喜欢可以看看，下载。在这里的下载后，同步就好。 这里展示从app下载的表盘。 在More里面，有我们需要的功能，install custom file。安装我们下载的表盘。 点击 install custom file 选择我们下载的变盘，然后同步到手环上。 过程就结束了。 真的结束了吗？！ 还要下载好多一个个去试～ 哈哈哈哈 结束 祝好","categories":[{"name":"小米手环","slug":"小米手环","permalink":"http://blog.51ai.vip/categories/小米手环/"}],"tags":[]},{"title":"Mac OS自己安装的小软件","slug":"Mac-OS自己安装的小软件","date":"2021-05-06T03:06:20.000Z","updated":"2021-05-06T03:27:11.007Z","comments":true,"path":"2021/05/06/Mac-OS自己安装的小软件/","link":"","permalink":"http://blog.51ai.vip/2021/05/06/Mac-OS自己安装的小软件/","excerpt":"","text":"自己使用Mac一年多自己在19年12月换了mac 16” 笔记本。之前一直windwos，后来看很多讲师在讲课的时候都是mac本本。又觉得windws10更新频繁，还强制让我很不爽。 最后凑巧16”出来后，自己媳妇送了我一台。美滋滋～ 讲讲我说的小软件一些好玩的，实用的软件。 Bob Hidden Bar itsycal pap.er uPic Go2Shell uTools PicGo electerm BLEUnlock Clipy","categories":[{"name":"Mac","slug":"Mac","permalink":"http://blog.51ai.vip/categories/Mac/"}],"tags":[]},{"title":"SSH 指定端口访问","slug":"SSH-指定端口访问","date":"2021-03-13T10:21:50.000Z","updated":"2021-03-13T10:31:44.374Z","comments":true,"path":"2021/03/13/SSH-指定端口访问/","link":"","permalink":"http://blog.51ai.vip/2021/03/13/SSH-指定端口访问/","excerpt":"","text":"很尴尬今天测试，一个通过隧道远程到设备的功能。 隧道创建完成，然后我就要ssh到哪台设备。反复连接一直不通，心里万马奔腾啊！～ 查看配置没问题啊，怎么就！@#¥%！！！ 后来发现 自己的锅， ssh user@ip：prot Hahaha～～ SSH连接SSH 默认端口22，通常我们ssh 时候指令是这样的 ssh user@ip 指定端口指定端口 我很少用，即便是改端口的我也大部分终端软件去连的。 正确方式： ssh -p port user@ip 记忆深刻，这下很尴尬。 特此记录。","categories":[{"name":"SSH","slug":"SSH","permalink":"http://blog.51ai.vip/categories/SSH/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"http://blog.51ai.vip/tags/SSH/"}]},{"title":"解决/usr/local/go/pkg/darwin_amd64/runtime/cgo.a: permission denied问题","slug":"解决-usr-local-go-pkg-darwin-amd64-runtime-cgo-a-permission-denied问题","date":"2021-02-22T01:06:08.000Z","updated":"2021-02-22T01:23:41.710Z","comments":true,"path":"2021/02/22/解决-usr-local-go-pkg-darwin-amd64-runtime-cgo-a-permission-denied问题/","link":"","permalink":"http://blog.51ai.vip/2021/02/22/解决-usr-local-go-pkg-darwin-amd64-runtime-cgo-a-permission-denied问题/","excerpt":"","text":"最近Goland在run的时候发现一个问题open /usr/local/go/pkg/darwin_amd64/runtime/cgo.a: permission denied 情况具体是当我run的时候有问题。debug可以。根据错误提示看到是权限的事。 解决方式执行 sudo chown -R xxx:yyy /usr/local/go xxx 用户名， yyy 组名 命令的目的：更改go目录的所有者用户和组。 查看用户名&amp;用户组当前用户名 常用命令 who am i查看当前用户名和组 ls -la 参考https://github.com/golang/go/issues/37962","categories":[{"name":"Golang","slug":"Golang","permalink":"http://blog.51ai.vip/categories/Golang/"}],"tags":[]},{"title":"Grafana插件Plugin中文汉化","slug":"Grafana插件Plugin中文汉化","date":"2020-11-30T05:46:47.000Z","updated":"2020-11-30T07:11:19.787Z","comments":true,"path":"2020/11/30/Grafana插件Plugin中文汉化/","link":"","permalink":"http://blog.51ai.vip/2020/11/30/Grafana插件Plugin中文汉化/","excerpt":"","text":"汉化三方插件前面说过汉化Grafana的工作。目前在7.2.1上面，大部分已经完成。细节继续完善。今天考虑在第三方插件上做一些汉化。点到插件一看全是英文感觉很突出。领导看到了也不爽啊-.-！。 找个软的捏饼图在展示方面比较直观。Grafana上有一个插件Pie Chart。这个现象比较少，同时在一些模版上使用中。就拿这个热热身。 具体步骤 下载项目 项目地址：piechart-panel文件结构： 123git clone git@github.com:grafana/piechart-panel.gitcd piechart-panel # 进入到目录yarn install 我直接把项目clone到grafana存放插件的位置，我的grafana是为了测试run的一个docker镜像。把插件目录挂载到本机，代码clone到目录中。 汉化工作 根据上面目录看，主要修改文件都在src里面。IDE打开此项目，在src中修改需要编辑的文件。 图片举例，选项第一项选择图形类型。选项内容pie / donut。通过翻译我修改成了 派/甜甜圈。根据修改内容其他地方设计修改的都需要修改。我通过查询替换方式，在其他文件中修改了代码中的判断。例如上图右侧展示的文件类似。 build插件 修改完需要的内容之后，grafana是能识别到有一个插件，但没有build时候他会提示你没有build插件。就是他不认识你的项目代码。 这个怎么处理呢？看官方的文档 执行 yarn dev 123# 执行结束提示，美滋滋～✔ Bundling plugin in dev mode✨ Done in 4.91s. 执行完毕我们重启grafana就可以看到成果了。 对比下原来的版本和汉化后的版本： before： After： 测试&amp;调试 以上2，3步骤基本就是一个测试、调试的过程。 我开始先把所有配置项汉化。然后再处理选项参数。 接着build，重启grafana查看。如此往复达到预期目标。 我本机调试用docker启动grafana，测完删了容器就好了。 持续改进考虑持续处理某个插件，可以考虑fork原插件项目，remote add XXX源。然后新建分之来做自己的处理。master fetch XXX源 以跟踪上游的更新。这样自己项目安装插件时候拉自己的就好啦，美滋滋。","categories":[{"name":"Grafana","slug":"Grafana","permalink":"http://blog.51ai.vip/categories/Grafana/"}],"tags":[]},{"title":"docker-compose编排搭建prometheus+grafana+alertmanager+node-exporter+snmp-exporter","slug":"docker-compose编排搭建prometheus-grafana-alertmanager-node-exporter-snmp-exporter","date":"2020-11-17T05:02:50.000Z","updated":"2020-11-17T06:31:23.194Z","comments":true,"path":"2020/11/17/docker-compose编排搭建prometheus-grafana-alertmanager-node-exporter-snmp-exporter/","link":"","permalink":"http://blog.51ai.vip/2020/11/17/docker-compose编排搭建prometheus-grafana-alertmanager-node-exporter-snmp-exporter/","excerpt":"","text":"Docker-compose目前集成很多Exporter，加上grafana的image-renderer，后面又加上ping-exporter，很多东西加起来发现操作一次docker 很烦啊。 科普之后感觉自己对k8s还有有些发怵的。从简单的一个入手吧，选择了docker-compose。 Docker-Compose项目是Docker官方的开源项目，负责实现对Docker容器集群的快速编排。 安装安装方式看了一下，我选择直接下载bin文件方式： 123curl -L https://get.daocloud.io/docker/compose/releases/download/1.12.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose``` 通过 docker-compose version 看到版本信息算是安装完成。 编写docker-compose.yml 目录结构： 1234567891011121314151617181920212223├── docker-compose.yaml├── prometheus│ ├── rules │ │ └── *(rules).yaml/json│ ├── nodes│ │ └── *(nodes).yaml│ ├── data│ │ └── ... # 挂载prom的data数据│ └── prometheus.yaml├── alertmanager│ ├── templates│ │ └── *.tmpl│ └── alertmanager.yaml├── grafana│ ├── data│ │ ├── plugins #插件目录│ │ ├── png │ │ └── grafana.db│ └── grafana.ini├── snmp(snmp_exporter)│ └── snmp.yml└── blackbox(balck box-exporter) └── blackbox.yml 根据结构编写 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134version: \"3.8\"networks: monitor: driver: bridgeservices: snmp-exporter: image: prom/snmp-exporter:v0.19.0 container_name: snmp restart: always expose: - 9116 volumes: - \"./snmp/snmp.yml:/etc/snmp_exporter/snmp.yml\" networks: - monitor node-exporter: image: prom/node-exporter:v1.0.1 container_name: node-exporter volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - '--path.procfs=/host/proc' - '--path.rootfs=/rootfs' - '--path.sysfs=/host/sys' - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)' restart: unless-stopped expose: - 9100 networks: - monitor blackbox-exporter: image: prom/blackbox-exporter:v0.18.0 expose: - 9115 container_name: blackbox restart: unless-stopped volumes: - \"./blackbox/:/config\" command: - \"--config.file=/config/blackbox.yml\" networks: - monitor cadvisor: image: google/cadvisor:v0.33.0 container_name: cadvisor volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker:/var/lib/docker:ro restart: unless-stopped expose: - 8080 networks: - monitor depends_on: - prometheus prometheus: image: prom/prometheus:v2.22.1 container_name: prom restart: always user: \"0\" ports: - \"9090:9090\" volumes: - \"./prometheus/:/prometheus\" command: - \"--storage.tsdb.retention.time=60d\" - \"--config.file=/prometheus/prometheus.yml\" - \"--web.enable-lifecycle\" networks: - monitor depends_on: - blackbox-exporter - node-exporter - snmp-exporter alertmanager: image: prom/alertmanager:v0.21.0 restart: always container_name: alert volumes: - ./alertmanager/:/alert command: - '--config.file=/alert/alertmanager.yml' - '--storage.path=/alert' ports: - \"9093:9093\" networks: - monitor depends_on: - prometheus grafana: image: chenwl2016/grafana-chs:0.1.4 restart: always container_name: grafana user: \"0\" ports: - \"3000:3000\" environment: - \"GF_SECURITY_ADMIN_PASSWORD=helloGf\" - \"GF_RENDERING_SERVER_URL=http://renderer:8081/render\" - \"GF_RENDERING_CALLBACK_URL=http://grafana:3000/\" - \"GF_LOG_FILTERS=rendering:debug\" volumes: - ./grafana/:/grafana - ./grafana/data/:/var/lib/grafana networks: - monitor depends_on: - prometheus - renderer renderer: image: grafana/grafana-image-renderer:latest container_name: renderer ports: - \"8081:8081\" environment: - \"ENABLE_METRICS=true\" - \"RENDERING_MODE=clustered\" - \"RENDERING_CLUSTERING_MODE=context\" - \"RENDERING_CLUSTERING_MAX_CONCURRENCY=5\" networks: - monitor ​ 当前的配置，主要是文件存储到宿主机上。通过容器挂载卷到容器内部。存储到宿主机目录时prometheus与grafana 会有权限问题。 配置中我是在user: “0”账户下，挂载目录 prometheus/grafana 都是 root:root。如果你不是root 需要根据uid:gid进行对应的配置。 prometheus 目录下的nodes是file_sd的配置文件，结合实际考虑docker-compose 的具体细节。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/categories/Docker/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"http://blog.51ai.vip/tags/Grafana/"},{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"},{"name":"AlertManager","slug":"AlertManager","permalink":"http://blog.51ai.vip/tags/AlertManager/"},{"name":"Node-Exporter","slug":"Node-Exporter","permalink":"http://blog.51ai.vip/tags/Node-Exporter/"},{"name":"Snmp-Exporter","slug":"Snmp-Exporter","permalink":"http://blog.51ai.vip/tags/Snmp-Exporter/"},{"name":"Black-Exporter","slug":"Black-Exporter","permalink":"http://blog.51ai.vip/tags/Black-Exporter/"}]},{"title":"关闭Mac的Microsoft AutoUpdate","slug":"关闭mac的Microsoft-AutoUpdate","date":"2020-10-13T05:14:34.000Z","updated":"2022-01-17T06:48:24.443Z","comments":true,"path":"2020/10/13/关闭mac的Microsoft-AutoUpdate/","link":"","permalink":"http://blog.51ai.vip/2020/10/13/关闭mac的Microsoft-AutoUpdate/","excerpt":"","text":"最近使用Office 发现AutoUpdate一直会启动。我也不需要里面的更新。每次还要把它推出。 网上看到有两种方法，一种是暴力删除，另一种是通过权限限制。 暴力可不是我喜欢的方式，所以选择后者。 方法： 打开终端 12cd /Library/Application\\ Support/Microsoft/MAU2.0sudo chmod 000 Microsoft\\ AutoUpdate.app 两行命令后，输入密码就可以了。","categories":[],"tags":[{"name":"office","slug":"office","permalink":"http://blog.51ai.vip/tags/office/"}]},{"title":"申请Let's Encrypt HTTPS 证书脚本","slug":"申请Let-s-Encrypt-HTTPS-证书脚本","date":"2020-06-24T05:33:18.000Z","updated":"2020-06-24T06:00:28.833Z","comments":true,"path":"2020/06/24/申请Let-s-Encrypt-HTTPS-证书脚本/","link":"","permalink":"http://blog.51ai.vip/2020/06/24/申请Let-s-Encrypt-HTTPS-证书脚本/","excerpt":"","text":"最近需要到SSL证书，又想免懒。选择脚本来更新SSL证书文件 Let’s Encrypt是一个由非营利性组织互联网安全研究小组（ISRG）提供的免费、自动化和开放的证书颁发机构（CA）。简单的说，借助Let’s Encrypt颁发的证书可以为我们的网站免费启用HTTPS(SSL/TLS) 。 那我们通过一个脚本来申请： 脚本名称： acme.sh 安装acme.sh： curl https://get.acme.sh | sh 创建指令： alias acme.sh=~/.acme.sh/acme.sh 测试收否安装成功： acme.sh --Version出现版本，安装完成。 生成证书acme.sh --issue -d demo.com -d www.demo.con -w /home/wwwroot/demo.com –issue是acme.sh脚本用来颁发证书的指令；-d是–domain的简称，其后面须填写已备案的域名；-w是–webroot的简称，其后面须填写网站的根目录。 查看证书acme.sh --list Nginx 配置项目是Nginx，下面是对Nginx的配置。 acme.sh –installcert -d demo.com \\ –key-file /etc/nginx/ssl/demo.com.key \\ –fullchain-file /etc/nginx/ssl/fullchain.cer \\ –reloadcmd “service nginx force-reload” 通过 installcert 来完成安装，此处我们需要把*.key,fullchain.cer 文件拷贝到指定位置。最后通过reload命令让Nginx重载（force-reload 我环境中无法使用此参数，这里换成 restart）。 最后我们需要配置Nginx的443 server 123456789server &#123; listen 443 ssl; server_name demo.com; ssl on; ssl_certificate /etc/nginx/ssl/fullchain.cer; ssl_certificate_key /etc/nginx/ssl/esofar.cn.key; ... 到此基本上配置完成了。Acme.sh 通过定时任务可以实现定期更新。 查看 crontab -l acme.sh的更新维护acme 协议和 letsencrypt CA 都在频繁的更新, 因此 acme.sh 也经常更新以保持同步。 手动更新： acme.sh --upgrade 自动更新：acme.sh --upgrade --auto-upgrade 取消自动更新： acme.sh --upgrade --auto-upgrade 0","categories":[{"name":"HTTPS","slug":"HTTPS","permalink":"http://blog.51ai.vip/categories/HTTPS/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"http://blog.51ai.vip/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"http://blog.51ai.vip/tags/SSL/"}]},{"title":"GORM 创建联合约束/索引","slug":"GORM-创建联合约束-索引","date":"2020-06-11T03:50:55.000Z","updated":"2020-06-11T04:04:00.862Z","comments":true,"path":"2020/06/11/GORM-创建联合约束-索引/","link":"","permalink":"http://blog.51ai.vip/2020/06/11/GORM-创建联合约束-索引/","excerpt":"","text":"GROM创建联合索引之前提到一个联合约束，那么根据需求再次做一个演示： 12345678type Demo struct &#123; ID uint `gorm:\"primary_key\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt *time.Time `gorm:\"index;unique_index:name_d\"` Name string `gorm:\"unique_index:name_d\"` Status int &#125; 通过demo 迁移后，deleted_at 与 name 会形成一个联合约束。 -OK,完结-","categories":[{"name":"GORM","slug":"GORM","permalink":"http://blog.51ai.vip/categories/GORM/"}],"tags":[{"name":"GORM","slug":"GORM","permalink":"http://blog.51ai.vip/tags/GORM/"},{"name":"Golang","slug":"Golang","permalink":"http://blog.51ai.vip/tags/Golang/"}]},{"title":"解决约束&软删除冲突","slug":"解决约束-软删除冲突","date":"2020-06-11T03:15:55.000Z","updated":"2020-06-11T03:46:43.531Z","comments":true,"path":"2020/06/11/解决约束-软删除冲突/","link":"","permalink":"http://blog.51ai.vip/2020/06/11/解决约束-软删除冲突/","excerpt":"","text":"约束&amp;软删除冲突本咸鱼对数据库方面研究甚少。能存数据就没多考虑其他问题。尤其是在设计方面。都是按照接口或者业务推到一下就好了。这次考虑一个问题，学习了一个小问题的处理。就是标题所述 约束与软删除的冲突。 场景问题例子： 一表单 字段为： |:–|| id || name ||… || u_number || deleted_at | 考虑 u_number 唯一问题，添加 约束 UNIQUE。u_number 是可复用的一些唯一数据。 那么问题来了： 当操作软删除时候，deleted_at (类型 datetime) 填充删除时间后，我理想化数据已经被删除。当 u_number 被其他用户使用插入此表结果是失败的。 解决方式u_number 因为唯一，导致后续使用此前删除的数据是不可行的，如果直接删前者数据也是不太有B格，不科学的事情。通过 联合的约束来完善此事，deleted_at 正好是时间， 与其联合使用即解决此事。 约束不再是单一约束 u_number 修改成 u_number,deleted_at。 -OK，完结。-","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.51ai.vip/categories/MySQL/"}],"tags":[{"name":"DB","slug":"DB","permalink":"http://blog.51ai.vip/tags/DB/"}]},{"title":"Linux重启后Docker设置自动启动&容器自动启动设置","slug":"Linux重启后Docker设置自动启动-容器自动启动设置","date":"2020-05-18T03:03:48.000Z","updated":"2020-05-18T03:22:27.407Z","comments":true,"path":"2020/05/18/Linux重启后Docker设置自动启动-容器自动启动设置/","link":"","permalink":"http://blog.51ai.vip/2020/05/18/Linux重启后Docker设置自动启动-容器自动启动设置/","excerpt":"","text":"Linux系统重启后Docker自动启动 系统重启后，如果docker没有启动，那么docker下所有的服务就都挂了。 配置过一次总是忘记命令，这里特意记录一下： systemctl enable docker.service 容器自动启动配置容器配置好自动启动后，当docker运行后，容器也自动启动。这样能保证服务的稳定性。不用再登录到系统来操作各种容易启动问题。涉及到的参数为：--restart=always 参数有： no，默认策略，在容器退出时不重启容器 on-failure，在容器非正常退出时（退出状态非0），才会重启容器。例如：on-failure:3，在容器非正常退出时重启容器，最多重启3次 always，在容器退出时总是重启容器 unless-stopped，在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器 容器已存在更新重启配置可能容器我们已经生成了，后面想实现always这个参数，可以用到下面的命令：docker container update --restart=always 容器名XXX这样就达到了想要的目的。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"},{"name":"Docker","slug":"Linux/Docker","permalink":"http://blog.51ai.vip/categories/Linux/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/tags/Linux/"}]},{"title":"解决MAC软件提示已损坏或移到废纸篓","slug":"解决MAC软件提示已损坏或移到废纸篓","date":"2020-02-07T12:24:02.000Z","updated":"2020-04-14T06:55:05.124Z","comments":true,"path":"2020/02/07/解决MAC软件提示已损坏或移到废纸篓/","link":"","permalink":"http://blog.51ai.vip/2020/02/07/解决MAC软件提示已损坏或移到废纸篓/","excerpt":"","text":"系统版本macOS Catalina 10.15.1 方法一 允许任何来源的应用。 系统偏好设置 -&gt; 安全性和隐私： 在 允许从以下位置下载的应用程序 选项中选择 任何来源 在 Sierra 10.12 中可能看不到这个选项，开启此功能需要执行命令sudo spctl --master-disable, 输入密码就可以看到此选项。 方法二 如果上面发法还是打不开，可能需要此方法。 sudo xattr -r -d com.apple.quarantine /Applications/xxxx.app/ 这里的x x.app如果你不知道名字，可以通过 应用中查看应用简介中的名称与扩展名, 或者在Applications目录下输入名称补全","categories":[{"name":"note","slug":"note","permalink":"http://blog.51ai.vip/categories/note/"}],"tags":[{"name":"MAC","slug":"MAC","permalink":"http://blog.51ai.vip/tags/MAC/"}]},{"title":"Mac book pro 终端走代理配置","slug":"Mac-book-pro-终端走代理配置","date":"2020-01-20T00:13:10.000Z","updated":"2020-09-15T01:24:23.587Z","comments":true,"path":"2020/01/20/Mac-book-pro-终端走代理配置/","link":"","permalink":"http://blog.51ai.vip/2020/01/20/Mac-book-pro-终端走代理配置/","excerpt":"","text":"mac 终端走ssr代理前提是你已经知道怎么使用shadowsocks软件，并且可以出去之后。 看下自己ssr 代理端口号是多少高级设置看下 本地Socks5监听端口记住这个端口号。后面：mac 现在默认终端是用的zsh编辑 vi ～/.zshrc在最后加入//alias 后面的名字自己可以按照习惯定义， 比如我定义proxy 是 ss。 每当我需要时候 ss 一下就可以了。 不需要的时候执行第二句。 12//端口按照你的来配置alias unproxy='unset all_proxy'alias proxy='export all_proxy=socks5://127.0.0.1:1086' 测试：首先在没有走ss 的时候， curl cip.cc 得到一个国内的信息。当使用ss之后， 再通过这个查询就可以看到变化了。 为了便捷，我觉得这个命令也可以设置成别名方式。 设置一个where 每次当我迷茫不知道自己出没出去的时候，就可以 输入where 看下。alias where=&#39;curl cip.cc&#39;","categories":[{"name":"note","slug":"note","permalink":"http://blog.51ai.vip/categories/note/"}],"tags":[{"name":"macbook","slug":"macbook","permalink":"http://blog.51ai.vip/tags/macbook/"},{"name":"terminal","slug":"terminal","permalink":"http://blog.51ai.vip/tags/terminal/"}]},{"title":"golang.org/x/xerrors：undefined: errors.Frame","slug":"golang-org-x-xerrors：undefined-errors-Frame","date":"2020-01-16T11:05:39.000Z","updated":"2020-04-14T06:55:05.119Z","comments":true,"path":"2020/01/16/golang-org-x-xerrors：undefined-errors-Frame/","link":"","permalink":"http://blog.51ai.vip/2020/01/16/golang-org-x-xerrors：undefined-errors-Frame/","excerpt":"","text":"项目初始化遇到问题错误为： 1234../go/pkg/mod/golang.org/x/xerrors@v0.0.0-20190410155217-1f06c39b4373/adaptor_go1_13.go:16:14: undefined: errors.Frame../go/pkg/mod/golang.org/x/xerrors@v0.0.0-20190410155217-1f06c39b4373/format_go1_13.go:12:18: undefined: errors.Formatterexit status 2exit status 1 通过科普得到一个方法：go get -u golang.org/x/xerrors 问题解决了。","categories":[{"name":"Golang","slug":"Golang","permalink":"http://blog.51ai.vip/categories/Golang/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"http://blog.51ai.vip/tags/Golang/"}]},{"title":"Golang 环境准备","slug":"Golang-环境准备","date":"2020-01-16T10:51:34.000Z","updated":"2020-04-14T06:55:05.109Z","comments":true,"path":"2020/01/16/Golang-环境准备/","link":"","permalink":"http://blog.51ai.vip/2020/01/16/Golang-环境准备/","excerpt":"","text":"安装GOlang环境:macOS shell: zsh 安装步骤： 12brew update &amp;&amp; brew upgrade # 更新brew install go # 安装 go 配置环境变量我的本shell 是zsh 下面是按照zsh配置：如果需要修改默认的环境变量配置修改 vim ~/.bash_profile 或 vim ~/.zshrc 123456789# GOROOT安装的路径export GOROOT=/usr/local/Cellar/go/1.9/libexec#GOPATH root binexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBIN#GOPATHexport GOPATH=$HOME/go#GOPATH binexport PATH=$PATH:$GOPATH/bin 退出保存后，使文件生效 source ~/.zshrc=","categories":[{"name":"Golang","slug":"Golang","permalink":"http://blog.51ai.vip/categories/Golang/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"http://blog.51ai.vip/tags/Golang/"}]},{"title":"yarn install phantomjs-prebuilt: Command failed.","slug":"yarn-install-phantomjs-prebuilt-Command-failed","date":"2020-01-16T06:21:26.000Z","updated":"2020-04-14T06:55:05.123Z","comments":true,"path":"2020/01/16/yarn-install-phantomjs-prebuilt-Command-failed/","link":"","permalink":"http://blog.51ai.vip/2020/01/16/yarn-install-phantomjs-prebuilt-Command-failed/","excerpt":"","text":"项目yarn install 出现phantomjs-prebuilt： Command failed.自己在项目中发现执行 yarn install时候，一直卡住没走完。 最后报错， error phantomjs-prebuilt： Command failed. 可以看到错误中，他是从 github.com/Medium/… 感觉就是没下载成功吧。 最开始以为网络问题，翻墙等方式都试过后发现还是没完成。 没办法，借助网络得知。可以轻松搞定： npm config set phantomjs_cdnurl=http://cdn.npm.taobao.org/dis…yarn config set “phantomjs_cdnurl” “https://npm.taobao.org/mirrors/phantomjs&quot; 看你是npm 还是node。按照上面方式设置一下。 rm -rf path/node_moudels yarn install 解决问题，美滋滋。 引用地址","categories":[{"name":"note","slug":"note","permalink":"http://blog.51ai.vip/categories/note/"}],"tags":[{"name":"yarn","slug":"yarn","permalink":"http://blog.51ai.vip/tags/yarn/"},{"name":"js","slug":"js","permalink":"http://blog.51ai.vip/tags/js/"}]},{"title":"MySQL5.7修改root密码","slug":"MySQL5-7修改root密码","date":"2020-01-15T07:23:54.000Z","updated":"2020-04-14T06:55:05.113Z","comments":true,"path":"2020/01/15/MySQL5-7修改root密码/","link":"","permalink":"http://blog.51ai.vip/2020/01/15/MySQL5-7修改root密码/","excerpt":"","text":"最近维护一个MySQL数据库，由于各种原因，密码已经不知道了。现在让我在这台服务器上使用里面的MySQL数据库。 怎么办？ 首先问了一圈没有人知道。那么只能靠自己了。 查看软件版本: mysql --version 之后通过神奇的Google科普了一下。知道了具体的方法： 关闭mysql服务。 修改my.conf在里面[mysqld] 下面最后加入一行 123[mysqld]...skip-grant-tables 修改完保存退出。 重启mysql服务。 mysql 进入mysql 不需要密码了。 show databases; 查看数据库 use mysql; 选择 mysql 数据库 在此数据库执行更新语句（修改root用户的密码为root）： update user set authentication_string=password(&#39;root&#39;) where user=&#39;root&#39;; flush privileges; 更新权限 退出mysql 把最开始my.conf加入的语句删除。 重启mysql服务 最后可以通过设置的密码登陆数据库了。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.51ai.vip/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.51ai.vip/tags/MySQL/"}]},{"title":"Prometheus-SNMP_Exporter Generator","slug":"Prometheus-SNMP-Exporter-Generator","date":"2019-12-24T07:26:33.000Z","updated":"2020-11-19T06:51:30.654Z","comments":true,"path":"2019/12/24/Prometheus-SNMP-Exporter-Generator/","link":"","permalink":"http://blog.51ai.vip/2019/12/24/Prometheus-SNMP-Exporter-Generator/","excerpt":"","text":"Prometheus-SNMP Exporter 生成器从generator.yml读取并写入snmp.yml。 之前在说Prometheus-snmp_export部署时,没有具体提到snmp.yml的生成器是怎么生成的.几乎用的都是github上的snmp.yml文件(只在demo中添加了auth配置). 因为刚好所有通用的指标都取得通用的mib树. 在后期我搜集设备的信息需要一些私有mib的数据,这时候需要自己通过生成器来生成snmp.yml. Generator 的操作步骤下载需要的程序(Docker方式跳过此步骤)123456789# Debian-based distributions.sudo apt-get install unzip build-essential libsnmp-dev # Debian-based distros# Redhat-based distributions.sudo yum install gcc gcc-g++ make net-snmp net-snmp-utils net-snmp-libs net-snmp-devel # RHEL-based distrosgo get github.com/prometheus/snmp_exporter/generatorcd $&#123;GOPATH-$HOME/go&#125;/src/github.com/prometheus/snmp_exporter/generatorgo buildmake mibs(不建议直接make) 这里直接make mibs 可能会失败,在make文件里设置的源有些已经不能访问了或执行出现错误. 我建议先下载好mibs ,我已经上传github. 建议自行搜集mib 不执行make mibs会方便一些 把所有的mib放入mibs 目录下. 需要准备好所有需要涉及到的mib文件. 除了公有的mib,我们还需要监控目标设备的私有mib.思科/华为之类的会提供这些mib,像锐捷这种需要和商务部联系. 一些mib: https://github.com/netdisco/netdisco-mibs https://github.com/pgmillon/observium/tree/master/mibs https://github.com/librenms/librenms/tree/master/mibs 当我们准备好所有的mib后,需要编写一个generator.yml.下面是一个翻译的官方文档(翻译比较烂,自行查阅原文)): 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778modules: module_name: # 模块名称。您可以根据需要拥有任意数量的模块。 walk: # 要walk的OID列表。 也可以是SNMP对象名称或特定实例。 - 1.3.6.1.2.1.2 # 与“接口”相同。 - sysUpTime # 与“ 1.3.6.1.2.1.1.3”相同。 - 1.3.6.1.2.1.31.1.1.1.6.40 # 索引为“ 40”的“ ifHCInOctets”的实例。 version: 2 # 要使用的SNMP版本。 默认2。 # 1将使用GETNEXT，2和3将使用GETBULK。 max_repetitions: 25 # 使用GET / GETBULK请求多少个对象，默认为25。 # 对于有故障的设备，可能需要减少。 retries: 3 # 重试失败请求的次数，默认为3。 timeout: 10s # 每次步行的超时时间，默认为10秒。 auth: # 社区字符串与SNMP v1和v2一起使用。 默认为“ public”。 community: public # v3具有不同且更复杂的设置。 # 需要哪些取决于security_level。 # 还列出了NetSNMP命令上的等效选项，例如snmpbulkwalk和snmpget。 # 请参见snmpcmd（1）。 username: user # 必需，无默认值。 NetSNMP的-u选项。 security_level: noAuthNoPriv # 默认为noAuthNoPriv。 NetSNMP的-l选项。 # 可以是noAuthNoPriv，authNoPriv或authPriv。 password: pass # 没有默认值。 也称为authKey，NetSNMP的-A选项。 # 如果security_level是authNoPriv或authPriv，则为必需。 auth_protocol: MD5 # MD5或SHA，默认为MD5。 -NetSNMP的选项。 # 如果security_level为authNoPriv或authPriv，则使用此属性。 priv_protocol: DES # DES或AES，默认为DES。 NetSNMP的-x选项。 # 如果security_level为authPriv，则使用。 priv_password: otherPass # 没有默认值。 也称为privKey，NetSNMP的-X选项。 # 如果security_level是authPriv，则为必需。 context_name: context # 没有默认值。 NetSNMP的-n选项。 # 如果在设备上配置了上下文，则为必需。 lookups: # 要执行的查找的可选列表。 # “keep_source_indexes”的默认值为false。 # 索引必须唯一，才能使用此选项。 # 如果表的索引是bsnDot11EssIndex，则通常是该表结果度量的标签。 # 相反,使用索引查找bsnDot11EssSsid表条目，并使用该值创建一个bsnDot11EssSsid标签。 - source_indexes: [bsnDot11EssIndex] lookup: bsnDot11EssSsid drop_source_indexes: false # 如果为true，则删除此查找的源索引标签。 # 当新索引唯一时，这可以避免标签混乱。 overrides: # 允许每个模块覆盖MIB的位 metricName: ignore: true # 从输出中删除度量。 regex_extracts: Temp: # 将创建一个新的度量，并将其附加到metricName上，成为metricNameTemp。 - regex: '(.*)' # 正则表达式从返回的SNMP walk的值中提取一个值。 value: '$1' # 结果将解析为float64，默认为$1。 Status: - regex: '.*Example' value: '1' - regex: '.*' value: '0' type: DisplayString # 覆盖度量标准类型，可能的类型有： # gauge: 带gauge的整数。 # counter: 带类型计数器的整数。 # OctetString: 一个位字符串，呈现为0xff34。 # DateAndTime: RFC 2579日期和时间字节序列。如果设备没有时区数据，则使用UTC。 # DisplayString: ASCII或UTF-8字符串。 # PhysAddress48: 一个48位的MAC地址，呈现为00:01:02:03:04:ff。 # Float: 一个32位浮点值，带有类型gauge。 # Double: 一个64位浮点值，带有类型gauge。 # InetAddressIPv4: IPv4地址，呈现为1.2.3.4。 # InetAddressIPv6: IPv6地址，呈现为0102:0304:0506:0708:090A:0B0C:0D0E:0F10。 # InetAddress: 每个RFC 4001有一个InetAddress。必须以InetAddressType开头。 # InetAddressMissingSize: 因索引中没有大小而违反RFC 4001第4.1节的InetAddress。 # 必须以InetAddressType开头。 # EnumAsInfo: 为其创建单个时间序列的枚举。适用于恒定值。 # EnumAsStateSet: 每个状态具有时间序列的枚举。适用于可变低基数枚举。 # Bits: 一种RFC2578位结构，它产生一个具有每位时间序列的状态集。 下面提供一个自己编写的generator.yml 12345678910111213141516171819202122232425262728293031323334353637modules: ruijie_mib: walk: - interfaces - ifXTable - sysUpTime - sysName - myMemoryPoolCurrentUtilization - myCPUUtilization5Sec timeout: 12s version: 2 auth: community: Monitor@#@Jkj lookups: - source_indexes: [ifIndex] lookup: ifAlias - source_indexes: [ifIndex] lookup: ifDescr - source_indexes: [ifIndex] lookup: 1.3.6.1.2.1.31.1.1.1.1 overrides: ifAlias: ignore: true ifDescr: ignore: true ifName: ignore: true ifType: type: EnumAsInfo sysDescr: type: DisplayString sysLocation: type: DisplayString ifPhysAddress: type: PhysAddress48 sysName: type: DisplayString 解释一下此配置的目的: 模块名称 ruijie_mib 通过名字可以知道是作用锐捷设备 walk 中, 是需要获取的指标. 其中前四个是共有mib获取到的,后面是私有mib获取到的. timeout 超时定义12秒 version snmp协议是v2 auth 定义的团体名 looksups 通过索引查找列表 overrides 前三个指标删除,后面几项是定义了他们的数据类型. 万事具备,只差执行.准备工作完成之后,就可以执行程序了. bin执行12export MIBDIRS=mibs./generator generate 执行后,可以看到snmp.yml. Docker方式通过dicker方式时，除上面需要的 mibs 文件夹和 generate.yml 再生成一个容器就好了。 pull镜像 docker pull prom/snmp-exporter:latest (查看具体版本)[https://hub.docker.com/r/prom/snmp-exporter/tags] 镜像通过挂在宿主机文件后，通过generate.yml生成snmp.yml 目录结构： 12./generate.yml./mibs 执行生成snmp.yml docker run -ti -v &quot;${PWD}:/opt/&quot; prom/snmp-generator generate 此容器挂载了一个目录，此目录下包含之前准备的 mibs 文件夹和 generate.yml。 执行完毕会在目录中生成 snmp.yml 文件。 出现错误排查： generate 命令改成 parse_errors 通常这样使用： docker run -ti -v &quot;${PWD}:/opt/&quot; snmp-generator parse_errors | head 生成出现问题两个方向： generate.yml 编写存在错误，格式 或者 指令。 可参考官方提供模版测试。 mib文件准备不足，缺少mib文件。可通过官方介绍提供的地址。我在github上分享了自己收集一些mib文件","categories":[{"name":"SNMP","slug":"SNMP","permalink":"http://blog.51ai.vip/categories/SNMP/"}],"tags":[{"name":"SNMP","slug":"SNMP","permalink":"http://blog.51ai.vip/tags/SNMP/"},{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"},{"name":"SNMP_Exporter","slug":"SNMP-Exporter","permalink":"http://blog.51ai.vip/tags/SNMP-Exporter/"}]},{"title":"Prometheus告警模板详解","slug":"Prometheus告警模板详解","date":"2019-12-04T03:51:43.000Z","updated":"2020-04-14T06:55:05.115Z","comments":true,"path":"2019/12/04/Prometheus告警模板详解/","link":"","permalink":"http://blog.51ai.vip/2019/12/04/Prometheus告警模板详解/","excerpt":"","text":"目的之前配置告警之后,可以发送告警信息.但对于数据具体的结构信息,在模板中数据读取都比较懵.原因是不太清除警报都提供了哪些数据,除了我们设置的信息,还有没有其他的信息. 告警数据结构官方docs 推送数据结构: 名称类型解释备注Receiverstring定义将通知发送到的接收者的名称(slack，电子邮件等)接收者名称Statusstring如果至少一个警报正在触发，则定义为触发，否则解决(Firing/Resolved)通过状态可以知道,是触发警报,还是警报已经恢复.便于区分状态.只有这两个状态,要么触发,要么恢复.AlertsAlert该组中所有警报对象的列表(请参见下文)警报提供的数据都在此列表中.列表下面会详细解读GroupLabelsKV这些警报按标签分组键值对数据,里面是我们在alertManager中配置分组(group_by)的数据CommonLabelsKV所有警报共有的标签很好理解,所有警报都共同有的标签.CommonAnnotationsKV所有警报的通用注释集。用于获取有关警报的更多其他信息字符串通用的注释(Annotations)ExternalURLstring反向链接到发送通知的Alertmanager此连接,点击会跳转到AlertManager.警报管理地址. Alerts数据 名称 类型 解释 备注 Status string 定义警报是否已解决或当前正在触发 警报状态(Firing/Resolved) Labels KV 警报上要贴的一组标签 警报设置中附加的标签 Annotations KV 警报的一组注释 顾名思义 StartsAt time.Time 警报开始触发的时间。如果省略，则当前时间由Alertmanager分配 警报触发时间 EndsAt time.Time 仅在知道警报的结束时间时设置。否则设置为自收到最后一个警报以来的时间的可配置超时时间 警报恢复时间(这个时间我不太清除到底是不是正确的,配置中也会有恢复超时时间,如果超时了,应该也会被认为恢复吧) GeneratorURL string 标识此警报的原因实体的反向链接 跳转警报图形数据的连接 KV数据的处理方式KV结构很简单,键值对.通过键获取对应的值.下面提供了一些方法处理这种结构的一些方法. 方法名 参数 返回值 解释 说明 SortedPairs - 对（键/值字符串对的列表） 返回键/值对的排序列表 通过此方法可以获得排序后的键值对列表数据 Remove []string KV 返回没有给定键的键/值映射的副本 当我们不希望KV数据种出现某些字段,通过此方法可以得到 Names - []string 返回LabelSet中标签名称的名称 通过此方法可以获得KV数据中所有键 Values - []string 返回LabelSet中值的列表 通过此方法可以获得KV数据中所有值 字符串相关方法警报提供的数据是通过GO模板解析的,GO模板的功能通过GO模板文档可以了解. 下面提供了一些处理字符串的方法: 微信通知的DEMO 上图中是微信接受的通知,下面展示通知模板的代码. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123;&#123;- define &quot;_alert_list&quot; -&#125;&#125;&#123;&#123;- range .Alerts.Firing -&#125;&#125;-----------------------告警类型：&#123;&#123; .Labels.alertname &#125;&#125;告警主题: &#123;&#123; .Annotations.summary &#125;&#125;告警详情: &#123;&#123; .Annotations.description &#125;&#125;触发时间: &#123;&#123; (.StartsAt.Add 28800e9).Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;&#123;&#123; end -&#125;&#125;---------结束-----------------&#123;&#123;- end -&#125;&#125;&#123;&#123;- define &quot;_resolve_list&quot; -&#125;&#125;&#123;&#123;- range .Alerts.Resolved -&#125;&#125;**************************告警类型：&#123;&#123; .Labels.alertname &#125;&#125;告警主题: &#123;&#123; .Annotations.summary &#125;&#125;告警详情: &#123;&#123; .Annotations.description &#125;&#125;触发时间: &#123;&#123; (.StartsAt.Add 28800e9).Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;恢复时间: &#123;&#123; (.EndsAt.Add 28800e9).Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;&#123;&#123; end -&#125;&#125;************结束*****************&#123;&#123;- end -&#125;&#125;&#123;&#123;- define &quot;wechat.message&quot; -&#125;&#125;&#123;&#123;- if and (gt (len .Alerts.Firing) 0) (gt (len .Alerts.Resolved) 0) -&#125;&#125;告警数量:&#123;&#123;.Alerts.Firing | len&#125;&#125;告警设备:&#123;&#123; .GroupLabels.server&#125;&#125;&#123;&#123; template &quot;_alert_list&quot; . &#125;&#125;====================================告警恢复:&#123;&#123;len .Alerts.Resolved&#125;&#125;告警设备:&#123;&#123; .GroupLabels.server&#125;&#125;&#123;&#123; template &quot;_resolve_list&quot; . &#125;&#125;&#123;&#123;- else -&#125;&#125; &#123;&#123;- if gt (len .Alerts.Firing) 0 -&#125;&#125;告警数量:&#123;&#123;.Alerts.Firing | len&#125;&#125;告警设备:&#123;&#123; .GroupLabels.server&#125;&#125; &#123;&#123; template &quot;_alert_list&quot; . &#125;&#125; &#123;&#123;- end -&#125;&#125; &#123;&#123;- if gt (len .Alerts.Resolved) 0 -&#125;&#125;告警恢复:&#123;&#123;len .Alerts.Resolved&#125;&#125;告警设备:&#123;&#123; .GroupLabels.server&#125;&#125;&#123;&#123; template &quot;_resolve_list&quot; . &#125;&#125; &#123;&#123;- end -&#125;&#125;&#123;&#123;- end -&#125;&#125;&#123;&#123;- end -&#125;&#125; 其中告警设备 server 这个标签是自定义的.如果没有可以删除此行或根据自己标签定义.","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"AlertManager","slug":"AlertManager","permalink":"http://blog.51ai.vip/tags/AlertManager/"}]},{"title":"Prometheus标签处理&服务发现","slug":"Prometheus标签处理-服务发现","date":"2019-12-03T07:14:16.000Z","updated":"2020-04-14T06:55:05.115Z","comments":true,"path":"2019/12/03/Prometheus标签处理-服务发现/","link":"","permalink":"http://blog.51ai.vip/2019/12/03/Prometheus标签处理-服务发现/","excerpt":"","text":"标签处理的重要性之前的配置中提到了标签的处理,不过由于写的是静态的配置,标签可以自己设置或者不设置都可以. 当使用服务发现之后发现标签处理的重要性提升了更高的级别. 标签处理12345678910111213141516171819202122232425262728 - job_name: 'node' static_configs: - targets: ['172.16.23.110:9100','172.16.23.111:9100'] metric_relable_configs: #通过正则重命名标签 - action: replace #replace替换是默认动作。keep（只参加匹配标签的实例）、drop（不采集匹配正则的实例）、labelkeep\\labeldrop(对标签进行过滤处理而非实例)等动作 source_labels: ['job'] #原标签，job是默认就会产生的标签，这里job标签的值是node regex: (.*) #正则匹配，这里匹配job标签内的内容，也就是node replacement: beijing #替换成什么内容，如果写$1就是将正则里读取的值 target_label: idc #把替换内容赋值给idc标签 - action: labeldrop #删除标签 regex: job #把原job标签删除- job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] labels: location: bj3 relabel_configs: - action: replace source_labels: ['job'] regex: (.*) replacement: $1 target_label: server 以上两个例子都是替换标签,job:node中,删除了前job标签,下面的job新增了’server’标签内容取的job内容,但没删除job标签. 通过标签我们组成多维模型.可以对标签重命名,删除,过滤信息等. 服务发现之前配置中的静态配置需要一个一些写配置,设备或者服务多的时候容易头大. 这里可以通过服务发现简化手动配置工作. Prometheus支持多种服务发现机制,例如: consul、dns、openstack、file、kubernetes等. 这里举例file.比较简单的方式. file机制中:需要提供文件来获取内容.文件格式为YAML 或 JSON格式. prometheus配置: 1234567scrape_configs: - job_name: &apos;prometheus&apos; file_sd_configs: - files: [&apos;/usr/local/prometheus/files_sd_configs/*.yaml&apos;] ##指定服务发现文件位置 refresh_interval: 5s ##刷新间隔改为5秒 Prometheus 每5秒扫描一次指定位置的配置文件. 服务发现文件格式: 123- targets: ['localhost:9090'] # 监控目标 labels: # 配置标签 server: local","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"}]},{"title":"M3DB笔记","slug":"M3DB笔记","date":"2019-11-29T09:41:43.000Z","updated":"2020-04-14T06:55:05.112Z","comments":true,"path":"2019/11/29/M3DB笔记/","link":"","permalink":"http://blog.51ai.vip/2019/11/29/M3DB笔记/","excerpt":"","text":"M3DB笔记前阵子研究prometheus,初期没有考虑存储问题.本地默认存储30天数据. 监控已经折腾完毕,现在需要来处理存储的方案. 通过互联网的科普,发现目前有两个方案可以解决这个问题. thanos M3DB thanos是需要存储云端数据(本地存储官方不推荐).不符合我们的考虑范围内.那就来学习M3DB了. 简介 M3可以在较长的保留时间内可靠地存储大规模指标。为了向更广泛的社区中的其他人提供这些好处，我们决定开放M3平台作为Prometheus的远程存储后端，Prometheus是一种流行的监控和警报解决方案。正如其文档所述，Prometheus的可扩展性和耐用性受到单个节点的限制。 M3平台旨在为Prometheus指标提供安全，可扩展且可配置的多租户的存储。 M3于2015年发布，目前拥有超过66亿个时间序列。 M3每秒聚合5亿个指标，并在全球范围内（使用M3DB）每秒持续存储2000万个度量指标，批量写入将每个指标持久保存到区域中的三个副本。它还允许工程师编写度量策略，告诉M3以更短或更长的保留时间（两天，一个月，六个月，一年，三年，五年等）以特定的粒度（一秒，十秒，一分钟，十分钟等）。这允许工程师和数据科学家使用与定义的存储策略匹配的度量标签（标签），在精细和粗粒度范围内智能地存储不同保留的时间序列。例如，工程师可以选择存储“应用程序”标记为“mobile_api”且“端点”标记为“注册”的所有度量标准，这些标记在10秒粒度下为30天，在一小时粒度下为5年。 相关组件 M3 CoordinatorM3 Coordinator是一种服务，用于协调上游系统（如Prometheus和M3DB）之间的读写操作。它还提供了管理API，用于设置和配置M3的不同部分。它是用户可以部署以访问M3DB的优势的桥梁，例如长期存储和与其他监控系统（如Prometheus）的多DC设置。 M3DBM3DB是一个分布式时间序列数据库，提供可扩展存储和时间序列的反向索引。它经过优化，具有成本效益和可靠的实时和长期保留指标存储和索引 M3 QueryM3 Query是一种服务，它包含一个分布式查询引擎，用于查询实时和历史指标，支持多种不同的查询语言。它旨在支持低延迟实时查询和可能需要更长时间执行的查询，聚合更大的数据集，用于分析用例 M3 AggregatorM3 Aggregator是一种作为专用度量聚合器运行的服务，它基于存储在etcd中的动态规则提供基于流的下采样。它使用领导者选举和聚合窗口跟踪，利用etcd来管理此状态，从而可靠地为低采样度量标准发送至少一次聚合到长期存储。这提供了成本有效且可靠的下采样和汇总指标。这些功能也存在于M3协调器中，但专用聚合器是分片和复制的，而M3协调器则不需要并且需要谨慎部署和以高可用性方式运行。还有一些工作要使用户更容易访问聚合器，而无需他们编写自己的兼容生产者和消费者。 入门 上面的组件通俗讲: prometheus 需要通过M3 Coordinator来协调存储与查询到M3DB,prometheus本地存储数据时间与这个没关系. 上面没有提到一个名字etcd服务.此服务推断拓扑\\配置功能. 如果db嵌入此服务就称为种子节点SeedNode. 官方提供了一个镜象,里面包含 M3 Coordinator + SeedNode. 拉取镜象:docker pull quay.io/m3db/m3dbnode:latest 启动名为m3db容器:docker run -d -p 7201:7201 -p 7203:7203 -p 9003:9003 --name m3db -v $(pwd)/m3db_data:/var/lib/m3db quay.io/m3db/m3dbnode:latest 该容器的端口为7201（用于管理集群拓扑），端口为7203，Prometheus用来刮除M3DB和M3Coordinator生成的度量，端口9003（用于读取和写入度量）已公开。 这时候m3db已经启动,需要创建一个初始命名空间.官方镜象默认是type:local,namespace:default. 这个可以进入容器查看到配置位置/etc/d3dbnode/m3dbnode.yml.如果我们创建其他命名空间需要在m3coordinator中配置好. curl -X POST http://localhost:7201/api/v1/database/create -d &#39;{ &quot;type&quot;: &quot;local&quot;, &quot;namespaceName&quot;: &quot;default&quot;, &quot;retentionTime&quot;: &quot;24h&quot; }&#39; 这里配置的参数除了type与namespaceName,还有一个保留时间.超过时间就被清除了.我们测试设置24小时可以了,如果我是监测自己的设备,不是生产的情况其实偷懒可以用这个单机存储设置一个较长时间.例如:1y(看你了兄嘚). 设置完稍等几分钟就可以使用了. 通过接口可以查看: curl http://localhost:7201/api/v1/placement 看到很多AVAILABLE 就是ok了. 访问localhost:7201/api/v1/openapi 可以看到官方提供的接口文档. 配置远程读写上面的库已经ok了,现在配置一下Prometheus.配置很简单只有两条.一条写,一条读. 123456remote_read: - url: \"http://localhost:7201/api/v1/prom/remote/read\" read_recent: trueremote_write: - url: \"http://localhost:7201/api/v1/prom/remote/write\" 监控指标我们这个用的是官方提供的镜象,嵌入式M3Coordinator的M3DB.所以按照下面这种方式配置. 123- job_name: 'm3' static_configs: - targets: ['&lt;HOST_NAME&gt;:7203']","categories":[{"name":"m3db","slug":"m3db","permalink":"http://blog.51ai.vip/categories/m3db/"}],"tags":[{"name":"m3db","slug":"m3db","permalink":"http://blog.51ai.vip/tags/m3db/"}]},{"title":"网络传输速度测试工具","slug":"网络传输速度测试工具","date":"2019-10-23T09:31:55.000Z","updated":"2020-04-14T06:55:05.123Z","comments":true,"path":"2019/10/23/网络传输速度测试工具/","link":"","permalink":"http://blog.51ai.vip/2019/10/23/网络传输速度测试工具/","excerpt":"","text":"网络传输测试软件 最近公司测试限速,搜集软件发现两款,iperf,LANSpeedTest. iperf,多平台. LANSpeedTest,读写显示,操作简单. 局域网测试传输,优先考虑UDP. iperfIperf可以报告带宽,延迟抖动和数据包丢失.官方文档安装不写了.跳过 iperf常用参数介绍123456789101112 -i 2 #表示每2秒显示一次报告 -w 80k #对于TCP方式，此设置为TCP窗口大小。对于UDP方式，此设置为接受UDP数据包的缓冲区大小，限制可以接受数据包的最大值 -B 192.168.122.1 #绑定到主机的多个地址中的一个。对于客户端来说，这个参数设置了出栈接口。对于服务器端来说，这个参数设置入栈接口。这个参数只用于具有多网络接口的主机。 #在Iperf的UDP模式下，此参数用于绑 定和加入一个多播组。使用范围在224.0.0.0至239.255.255.255的多播地址#常用客户端参数 -b 100m #用于udp测试时，设置测试发送的带宽，单位：bit/秒，不设置时默认为：1Mbit/秒 -c #指定服务端ip地址 -d #同时测试上行和下行 -t 10 #设置传输时间，为10秒 -P 5 #指定发起5个线程 UDP测试123456789服务端 iperf -u -s # -u表示以udp模式运行，-s表示作为服务端, 这里需要设置ip客户端 iperf -u -c 192.168.100.11 -b 100M -t 60 -i 2 #解释：在udp模式下，以100Mbps为数据发送速率，客户端到服务器192.168.100.11上传带宽测试，测试时间为60秒 iperf -u -c 192.168.100.11 5M -P 30 -t 6 #客户端同时向服务器端发起30个连接线程，以5Mbps为数据发送速率 iperf -u -c 192.168.100.11 -b 100M -d -t 60 #以100M为数据发送速率，进行上下行带宽测试 TCP测试1234567服务端 iperf -s客户端 iperf -c 192.168.100.11 -t 60 #在tcp模式下，客户端到服务器192.168.100.11上传带宽测试，测试时间为60秒。 iperf -c 192.168.100.11 -P 30 -t 60 #客户端同时向服务器端发起30个连接线程。 iperf -c 192.168.100.11 -d -t 60 -i 2 #进行上下行带宽测试。 测试结果结果中可以看到:30秒(-t)的测试,传递数据 70+ (-b参数), 监测的带宽约为20M . LANSpeedTest首先server端开启服务即可.LST_Server 程序开启.如图: 终端LAN_SpeedTest 程序.界面如图: 配置种可以配置数据大小:点击Config:具体配置自行参考里面的选项.这里设置10M的数据. 设定好目标IP,Folder or Server IP 这里填写. 单击 Start Test 等待结果. 图为检测中: 结果:检测结果和上面软件类似,约为20M.","categories":[{"name":"soft","slug":"soft","permalink":"http://blog.51ai.vip/categories/soft/"}],"tags":[{"name":"iperf","slug":"iperf","permalink":"http://blog.51ai.vip/tags/iperf/"},{"name":"LANSpeedTest","slug":"LANSpeedTest","permalink":"http://blog.51ai.vip/tags/LANSpeedTest/"}]},{"title":"Prometheus-AlertManager警告管理搭建与配置","slug":"Prometheus-AlertManager警告管理搭建与配置","date":"2019-10-19T01:40:15.000Z","updated":"2020-07-13T06:04:58.209Z","comments":true,"path":"2019/10/19/Prometheus-AlertManager警告管理搭建与配置/","link":"","permalink":"http://blog.51ai.vip/2019/10/19/Prometheus-AlertManager警告管理搭建与配置/","excerpt":"","text":"AlertManager AlertManager处理由客户端应用程序（如Prometheus服务器）发送的警报。它负责重复数据消除、分组，并将它们路由到正确的接收器集成（如电子邮件、PagerDuty或OpsGenie）。它还负责消除和抑制警报。 通过翻译官方文档可以了解到,AlertManager是负责为Prometheus(本身不会发送警报)发送警报的工具.AlertManager不是简单发送警报,可以消除重复警报,分组,抑制警报功能.并支持多接收器. Prometheus-&gt;触发定义的警报规则-&gt;AlertManager-&gt;发送警报到指定通知渠道. 为了能让Prometheus发送警报,我们需要: 搭建AlertManager服务. 定义AlertManager通知配置. 定义Prometheus警报规则并引入. 测试警报. 定义通知模板. 定义AlertManager通知配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566global: smtp_smarthost: 'smtp.163.com:25' # 邮箱smtp服务器代理 smtp_from: 'shitu-0071@163.com' # 发送邮箱名称 resolve_timeout: 5m # 处理超时时间，默认为5min smtp_auth_username: 'shitu-0071@163.com' # 邮箱帐户 smtp_auth_password: '******' # 邮箱授权码(注意是授权码,不知道自己查一下) wechat_api_url: 'https://qyapi.weixin.qq.com/cgi-bin/' # 企业微信地址# 定义模板信心templates: - 'template/*.tmpl'# 定义路由树信息route: group_by: ['alertname', 'cluster', 'service'] # 报警分组依据,设置后会按照设定值分组,例如instance,alertname等 # 同标签警告会在作为一组警报发送 group_wait: 10s # 组内等待时间,触发阈值后,XXs后发送本组警报 group_interval: 10s # 每个组之前间隔时间(group_by设定的值划分的组) repeat_interval: 1m # 重复发送警报的周期 (对于email配置中，此项不可以设置过低，否则将会由于邮件发送太多频繁，被smtp服务器拒绝) receiver: 'email' # 发送警报的接收者的名称 # 以下receivers name的名称 routes: - match: # 普通匹配 serverity: critical # 警告级别critical receiver: email # 通过邮件发送 - match_re: # 正则匹配 severity: ^(warning)$ # 匹配警告级别为warning的 receiver: wechat # 通过微信发送告警 - receiver: along # 定义接收者 match: # 匹配 severity: test # 等级为test# 定义警报接收者信息receivers: - name: 'email' # 警报 email_configs: # 邮箱配置 - to: '******@163.com' # 接收警报的email配置 html: '&#123;&#123; template \"test.html\" . &#125;&#125;' # 设定邮箱的内容模板 headers: &#123; Subject: \"[WARN] 报警邮件\"&#125; # 接收邮件的标题 webhook_configs: # webhook配置 - url: 'http://127.0.0.1:5001' send_resolved: true - name: 'wechat' wechat_configs: # 企业微信报警配置 - send_resolved: true to_party: '1' # 接收组的id agent_id: '1000002' # (企业微信--&gt;自定应用--&gt;AgentId) corp_id: '******' # 企业信息(我的企业--&gt;CorpId[在底部]) api_secret: '******' # 企业微信(企业微信--&gt;自定应用--&gt;Secret) message: '&#123;&#123; template \"test_wechat.html\" . &#125;&#125;' # 发送消息模板的设定# 一个inhibition规则是在与另一组匹配器匹配的警报存在的条件下，# 使匹配一组匹配器的警报失效的规则。两个警报必须具有一组相同的标签。 inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'critical' equal: ['instance'] # 已经发送的告警通知匹配到target_match和target_match_re规则， # 再有新的告警规则如果满足source_match # 或者定义的匹配规则，并且已发送的告警与新产生的告警中equal定义的标签完全相同， # 则启动抑制机制，新的告警不会发送。 以下是官方文档配置翻译的文档.供参考具体详细的配置介绍.不细看先略过到下个步骤. 路由块定义路由树中的节点及其子节点。如果未设置，则其可选配置参数将从其父节点继承。每个警报都在配置的顶级路由处进入路由树，该路由树必须与所有警报匹配（即没有任何配置的匹配器）。然后它遍历子节点。如果continue设置为false，则在第一个匹配的子级之后停止。如果匹配节点上的continue为true，则警报将继续与后续同级节点匹配。如果警报与节点的任何子节点不匹配（没有匹配的子节点，或者不存在），则基于当前节点的配置参数来处理警报。 123456789101112131415161718192021222324252627282930313233[ receiver: &lt;string&gt; ]# 用于将传入警报分组在一起的标签。 # 例如，针对cluster = A和alertname = LatencyHigh的多个警报将被分为一个组。# 要按所有可能的标签进行汇总，请使用特殊值'...'作为唯一的标签名称，例如：group_by：['...']# 这样可以有效地完全禁用聚合，并按原样传递所有警报。 # 除非您的警报量非常低或上游通知系统执行自己的分组，否则这不太可能是您想要的。[ group_by: '[' &lt;labelname&gt;, ... ']' ]# 警报是否应继续匹配后续的同级节点[ continue: &lt;boolean&gt; | default = false ]# 警报必须满足的一组相等匹配器才能匹配节点。match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]# 警报必须满足以匹配节点的一组正则表达式匹配器。match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ]# 最初等待为一组警报发送通知的时间。 # 允许等待禁止警报到达或为同一组收集更多初始警报。 （通常〜0秒到几分钟。）[ group_wait: &lt;duration&gt; | default = 30s ]# 发送有关新警报的通知之前要等待的时间，# 该通知将添加到已为其发送了初始通知的一组警报中。 （通常〜5m或更多。）[ group_interval: &lt;duration&gt; | default = 5m ]# 如果已成功发送警报，则等待多长时间才能再次发送通知。 （通常〜3h或更长时间）。[ repeat_interval: &lt;duration&gt; | default = 4h ]# 零个或多个子路由。routes: [ - &lt;route&gt; ... ] &lt;inhibit_rule&gt;当与另一组匹配器匹配的警报（源）存在时，禁止规则静默匹配匹配器集合的警报（目标）。对于相等列表中的标签名称，目标和源警报必须具有相同的标签值。从语义上讲，缺失的标签和空值的标签是一样的。因此，如果源警报和目标警报中均缺少equal中列出的所有标签名称，则将应用抑制规则。为了防止警报抑制自身，与规则的目标端和源端都匹配的警报不能被相同的警报（包括自身）抑制。但是，我们建议选择目标和源匹配器时，警报不会同时匹配双方。这很容易推理，也不会引发这种特殊情况。 1234567891011121314# 必须在警报中完成的匹配项才能被禁用target_match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]target_match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ]# 匹配器必须具有一个或多个警报才能使抑制生效source_match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]source_match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ]# 必须在源警报和目标警报中具有相等值的标签才能使抑制生效[ equal: '[' &lt;labelname&gt;, ... ']' ] 12345678910# 接收者的唯一名称name: &lt;string&gt;# 多个通知集成的配置(这里只列出三个其他请看官网)email_configs: [ - &lt;email_config&gt;, ... ]webhook_configs: [ - &lt;webhook_config&gt;, ... ]wechat_configs: [ - &lt;wechat_config&gt;, ... ] &lt;email_config&gt;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 是否通知已解决的警报[ send_resolved: &lt;boolean&gt; | default = false ]# 要向其发送通知的电子邮件地址to: &lt;tmpl_string&gt;# 发件人地址[ from: &lt;tmpl_string&gt; | default = global.smtp_from ]# 发送电子邮件的SMTP主机[ smarthost: &lt;string&gt; | default = global.smtp_smarthost ]# 要标识到SMTP服务器的主机名[ hello: &lt;string&gt; | default = global.smtp_hello ]# SMTP身份验证信息.[ auth_username: &lt;string&gt; | default = global.smtp_auth_username ][ auth_password: &lt;secret&gt; | default = global.smtp_auth_password ][ auth_secret: &lt;secret&gt; | default = global.smtp_auth_secret ][ auth_identity: &lt;string&gt; | default = global.smtp_auth_identity ]# SMTP TLS要求[ require_tls: &lt;bool&gt; | default = global.smtp_require_tls ]# TLS配置tls_config: [ &lt;tls_config&gt; ]# 电子邮件通知的HTML正文[ html: &lt;tmpl_string&gt; | default = '&#123;&#123; template \"email.default.html\" . &#125;&#125;' ]# 电子邮件通知的正文[ text: &lt;tmpl_string&gt; ]# 更多标题电子邮件标题键/值对,重写通知实现以前设置的任何头# 先前由通知实现设置的。[ headers: &#123; &lt;string&gt;: &lt;tmpl_string&gt;, ... &#125; ] &lt;webhook_config&gt;12345678# 是否通知已解决的警报[ send_resolved: &lt;boolean&gt; | default = true ]# 要向其发送HTTP POST请求的终结点url: &lt;string&gt;# http客户端的配置[ http_config: &lt;http_config&gt; | default = global.http_config ] 微信json 格式 123456789101112131415161718192021&#123; \"version\": \"4\", \"groupKey\": &lt;string&gt;, // 识别警报组的密钥（例如重复数据消除） \"status\": \"&lt;resolved|firing&gt;\", \"receiver\": &lt;string&gt;, \"groupLabels\": &lt;object&gt;, \"commonLabels\": &lt;object&gt;, \"commonAnnotations\": &lt;object&gt;, \"externalURL\": &lt;string&gt;, // 指向AlertManager的反向链接 \"alerts\": [ &#123; \"status\": \"&lt;resolved|firing&gt;\", \"labels\": &lt;object&gt;, \"annotations\": &lt;object&gt;, \"startsAt\": \"&lt;rfc3339&gt;\", \"endsAt\": \"&lt;rfc3339&gt;\", \"generatorURL\": &lt;string&gt; // 标识导致警报的实体 &#125;, ... ]&#125; &lt;wechat_config&gt; 123456789101112131415161718# 是否通知已解决的警报[ send_resolved: &lt;boolean&gt; | default = false ]# 与微信API通信时要使用的API密钥[ api_secret: &lt;secret&gt; | default = global.wechat_api_secret ]# 微信api网址[ api_url: &lt;string&gt; | default = global.wechat_api_url ]# 用于身份验证的公司ID[ corp_id: &lt;string&gt; | default = global.wechat_api_corp_id ]# 微信API定义的API请求数据[ message: &lt;tmpl_string&gt; | default = '&#123;&#123; template \"wechat.default.message\" . &#125;&#125;' ][ agent_id: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.agent_id\" . &#125;&#125;' ][ to_user: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.to_user\" . &#125;&#125;' ][ to_party: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.to_party\" . &#125;&#125;' ][ to_tag: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.to_tag\" . &#125;&#125;' ] 搭建AlertManager服务部署AlertManager可以通过官网https://prometheus.io/download/下载二进制文件.这里演示docker部署AlertManager服务.其他方式请参考官网. docker部署前,需要先完成配置文件的工作. 我在/home/along/下创建了一个配置文件 touch alertmanager.yml之后编辑 vi alertmanager.yml,具体看上文的配置介绍. 启动容器: 123docker run -d -p 9093:9093 --name alertmanagter-v /home/along/alertmanager.yml:/etc/alertmanager/alertmanager.ymlquay.io/prometheus/alertmanager 如果加载模板的话需要挂在一下模板目录(模板在下面有介绍):1234docker run -d -p 9093:9093 --name alert9093-v /home/along/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml-v /home/along/alertmanager/template:/alertmanager/templatequay.io/prometheus/alertmanager 服务端口9093,挂在刚才设定的配置文件. 访问IP:9093 可以查看AlertManager的web界面(类似prometheus的web界面). 定义Prometheus警报规则并引入配置配置警报规则文件警报规则文件顾名思义,你想监控的指标何时需要警报.例如设备温度超过多少要警告.创建alert.yml,touch alert.yml12345678910groups:- name: metricsUp # 定义这组告警的组名rules: - alert: 监测对象挂了 # 警报名 可理解为警告的标题 expr: up&#123;instance=\"192.168.23.11:9090\"&#125; == 0 # 判断某值的规则 for: 5m # 上面规则持续5分钟为0进行告警,5分钟内触发是pending状态 labels: # 定义警报标签 severity: waring # 定义警报等级为 waring annotations: # 备注描述 summary: \"设备: &#123;&#123; $labels.instance &#125;&#125; 已断开5分钟\" # 警告中呈现的具体信息可以写在这里 Prometheus引入配置警报规则是Prometheus引入的文件.Prometheus引入文件的方式: 12rule_files: - \"/usr/local/prometheus/alert.yml\" # 引入定义的警报规则 测试警报我们上面配置好之后,需要各服务已经读取到相关配置文件了之后开始测试.上面的规则是监测某个监控节点断开,手动断开一个节点.然后5分钟之后观察是否得到警报. 当由警报时收到的邮件为: 访问AlertManager页面也可以看到告警信息: 这里图例有些是演示用,与其他可能不存在关系.(不是同时截图的业务,图片仅供参考) 静默操作演示如果有些警报是我们调试的,例如我这里设置值偏低来演示ping值警报,如果我们测时候不想看到警报,可以通过静默来不让他总是发送警报. 之后点击create 就可以创建此警报的静默操作. 也可以通过正则,警报组名,实例等来静默各种警报. 定义通知模板默认模板我们看到了,他是默认的一个告警模板,在我们测试时候可以使用,如果面向用户使用者似乎这个模板不太友好.而且在面对多数据展示时,此模板也显得不是很清晰. 通过定义了模板,在触发不同警报可以通过AlertManager中,receivers选项来选择模板. 12345678templates: - 'template/*.tmpl' # 定义模板中心receivers: - name: 'email' # 警报 email_configs: # 邮箱配置 - to: '******@163.com' # 接收警报的email配置 html: '&#123;&#123; template \"test.html\" . &#125;&#125;' # 设定邮箱的内容模板 headers: &#123; Subject: \"[WARN] 报警邮件\"&#125; # 接收邮件的标题 这段配置中,可以看到警报通过test.html作为模板的.他的位置在上面的定义中可以看到是 template/test.html (如果模板定制有错误,警报可能为空板,不能正常显示内容)现在来配置这个test.html 在 /template/ 下创建 touch test.html模板基于Go的模板系统,详情点击这里如果不想深入连接可以结合默认模板模仿一下语法,默认模板点击这里 1234567891011121314151617181920&#123;&#123; define &quot;email.demo.html&quot; &#125;&#125;&lt;pre&gt;&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot;&gt; &lt;tr&gt; &lt;td&gt;报警名&lt;/td&gt; &lt;td&gt;设备&lt;/td&gt; &lt;td&gt;发现时间&lt;/td&gt; &lt;td&gt;详情&lt;/td&gt; &lt;/tr&gt; &#123;&#123; range $i, $alert := .Alerts &#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; index $alert.Labels &quot;alertname&quot; &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.Labels.instance &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.StartsAt.Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.Annotations.summary &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123; end &#125;&#125;&lt;/table&gt;&lt;/pre&gt;&#123;&#123; end &#125;&#125; 模板保存后,测试邮件接收情况: 模板时区问题Prometheus中所有时间都是UTC时间,为了便于我们展示友好时间(东八区),我们需要计算一下时间.修改模板时间: 1&lt;td&gt;&#123;&#123; ($alert.StartsAt.Add 28800e9).Format \"2006-01-02 15:04:05\" &#125;&#125;&lt;/td&gt; 参考ishenpingsongjiayangprometheus.io","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"},{"name":"AlertManager","slug":"Prometheus/AlertManager","permalink":"http://blog.51ai.vip/categories/Prometheus/AlertManager/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"},{"name":"AlertManager","slug":"AlertManager","permalink":"http://blog.51ai.vip/tags/AlertManager/"}]},{"title":"windows10家庭版启用组策略gpedit.msc","slug":"windows10家庭版启用组策略gpedit-msc","date":"2019-10-15T03:35:11.000Z","updated":"2020-04-14T06:55:05.122Z","comments":true,"path":"2019/10/15/windows10家庭版启用组策略gpedit-msc/","link":"","permalink":"http://blog.51ai.vip/2019/10/15/windows10家庭版启用组策略gpedit-msc/","excerpt":"","text":"启用组策略gpedit.msc家庭版很多功能不能使用,凑巧用的就是家庭版. 还想使用gpedit.msc来关闭windows10的更新.找到一个可行的方法. 需要创建一个脚本. 如果你没有编辑器,那么可以创建一个文本文档. 复制下面一段到本文中. 123456@echo offpushd \"%~dp0\"dir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientExtensions-Package~3*.mum &gt;List.txtdir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientTools-Package~3*.mum &gt;&gt;List.txtfor /f %%i in ('findstr /i . List.txt 2^&gt;nul') do dism /online /norestart /add-package:\"C:\\Windows\\servicing\\Packages\\%%i\"pause 如果编辑器直接复制一个文档另存到XX.cmd 即可. 如果是文本文档那么就是把后缀的.txt改成.cmd. 管理员身份运行这个脚本.等他走完会退出,win+r 即可使用gpedit.msc了. 美滋滋!~ 禁用windows10更新 win+r 输入gpedit.msc. “本地计算机策略”-“计算机配置”-“管理模板”-“Windows组件”-“Windows 更新”-“配置自动更新”. 点击配置自动更新设置为禁用","categories":[{"name":"windows","slug":"windows","permalink":"http://blog.51ai.vip/categories/windows/"}],"tags":[{"name":"windows","slug":"windows","permalink":"http://blog.51ai.vip/tags/windows/"}]},{"title":"Prometueus.yml配置文件说明","slug":"Prometueus-yml配置文件说明","date":"2019-10-09T07:20:58.000Z","updated":"2020-09-15T01:23:30.285Z","comments":true,"path":"2019/10/09/Prometueus-yml配置文件说明/","link":"","permalink":"http://blog.51ai.vip/2019/10/09/Prometueus-yml配置文件说明/","excerpt":"","text":"整体配置prometueus.yml 配置文件注解与说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849global: # 全局配置 scrape_interval: 15s # 默认值为 1m，用于设置每次数据收集的间隔 scrape_timeout: 10s # 默认10s,收集超时时间 evaluation_interval: 15s # 记录规则/告警的执行周期 默认1m external_labels: # 时间序列和警告与外部通信(远程存储/警报灯)时用的外部标签 monitor: 'ctmonitor'rule_files: # 指定告警规则文件&amp;记录文件 - \"/usr/local/prometheus/rules.yml\"alerting: # 告警管理配置 alert_relable_configs: # 修改告警内容 - alertmanagers: # 告警管理起配置 - static_configs: # 静态配置 - targets: # 警告器地址 - 172.16.23.12:9093# 用于配置 scrape 的 endpoint 配置需要 scrape 的 targets 以及相应的参数# 抓取(pull)，即监控目标配置。默认只有主机本身的监控配置 scrape_configs: # 抓取配置选项- job_name: prometheus # 默认情况下分配给刮削度量的作业名称。 scrape_interval: 5s # 从这项工作中获取目标的频率。 scrape_timeout: 3s # 每次获取超时时间 honor_timestamps: true # 默认false, 在获取时是否使用当前的时间戳 metrics_path: /metrics # 从目标获取度量的http资源路径。 scheme: http # static_configs: # 为此作业标记的静态配置目标的列表。 - targets: # 目监控标 - 172.16.23.12:9090 # 设备地址+端口- job_name: 'snmp-10.0.0.1' scrape_interval: 30s scrape_timeout: 20s static_configs: - targets: - 10.0.0.1 # SNMP设备,端口默认5060 metrics_path: /snmp params: module: [if_mib] relabel_configs: # 重定义标签 - source_labels: [__address__] # 需要修改的标签 target_label: __param_target # 改成的标签 - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 172.16.23.12:9117 各部分详解 部分官方文档的译文 官方文档中,使用了通用占位符来解释设定值的定义. 通用占位符由下面定义： \\&lt;boolean\\&gt;: 一个布尔值，包括true或者false. \\&lt;duration\\&gt;: 持续时间，与正则表达式[0-9]+(ms|smhdwy)匹配 \\&lt;labelname\\&gt;: 一个与正则表达式[a-zA-Z_][a-zA-Z0-9_]*匹配的字符串 \\&lt;labelvalue\\&gt;: 一个为unicode字符串 \\&lt;filename\\&gt;: 当前工作目录下的有效路径 \\&lt;host\\&gt;: 一个包含主机名或者IP地址，并且可以带上一个非必需的端口号的有效字符串 \\&lt;path\\&gt;: 一个有效的URL路径 \\&lt;scheme\\&gt;: 一个可以是http或者https的字符串 \\&lt;string\\&gt;: 一个正则表达式字符串 scrape_configs监控配置 &lt;scrape_configs&gt;配置采集目标1、根据配置的任务（job）以http/s周期性的收刮（scrape/pull）2、指定目标（target）上的指标（metric）。目标（target）3、可以以静态方式或者自动发现方式指定。Prometheus将收刮（scrape）的指标（metric）保存在本地或者远程存储上。 &lt;scrape_config&gt;部分指定一组描述如何刮除它们的目标和参数。 在一般情况下，一个scrape配置指定单个作业。 在高级配置中，这可能会改变。目标可以通过&lt;static_configs&gt;参数静态配置，也可以使用其中一种支持的服务发现机制动态发现。此外，&lt;relabel_configs&gt;允许在抓取之前对任何目标及其标签进行高级修改。其中&lt;job_name&gt;在所有scrape配置中必须是唯一的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# 默认分配给已抓取指标的job名称。job_name: &lt;job_name&gt;# 从job中抓取目标的频率.[ scrape_interval: &lt;duration&gt; | default = &lt;global_config.scrape_interval&gt; ]# 抓取此job时，每次抓取超时时间.[ scrape_timeout: &lt;duration&gt; | default = &lt;global_config.scrape_timeout&gt; ]# 从目标获取指标的HTTP资源路径.[ metrics_path: &lt;path&gt; | default = /metrics ]# honor_labels控制Prometheus如何处理已经存在于已抓取数据中的标签与Prometheus将附加服务器端的标签之间的冲突（\"job\"和\"instance\"标签，手动配置的目标标签以及服务发现实现生成的标签）。# # 如果honor_labels设置为\"true\"，则通过保留已抓取数据的标签值并忽略冲突的服务器端标签来解决标签冲突。## 如果honor_labels设置为\"false\"，则通过将已抓取数据中的冲突标签重命名为\"exported_ &lt;original-label&gt;\"（例如\"exported_instance\"，\"exported_job\"）然后附加服务器端标签来解决标签冲突。 这对于联合等用例很有用，其中应保留目标中指定的所有标签。# # 请注意，任何全局配置的\"external_labels\"都不受此设置的影响。 在与外部系统通信时，它们始终仅在时间序列尚未具有给定标签时应用，否则将被忽略。# 当设置为 true, 以拉取数据为准，否则以服务配置为准[ honor_labels: &lt;boolean&gt; | default = false ]# 配置用于请求的协议方案.[ scheme: &lt;scheme&gt; | default = http ]# 可选的HTTP URL参数.params: [ &lt;string&gt;: [&lt;string&gt;, ...] ]# 使用配置的用户名和密码在每个scrape请求上设置`Authorization`标头。 password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;secret&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个scrape请求上设置`Authorization`标头。 它`bearer_token_file`和是互斥的。[ bearer_token: &lt;secret&gt; ]# 使用配置的承载令牌在每个scrape请求上设置`Authorization`标头。 它`bearer_token`和是互斥的。[ bearer_token_file: /path/to/bearer/token/file ]# 配置scrape请求的TLS设置.tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL.[ proxy_url: &lt;string&gt; ]# Azure服务发现配置列表.azure_sd_configs: [ - &lt;azure_sd_config&gt; ... ]# Consul服务发现配置列表.consul_sd_configs: [ - &lt;consul_sd_config&gt; ... ]# DNS服务发现配置列表。dns_sd_configs: [ - &lt;dns_sd_config&gt; ... ]# EC2服务发现配置列表。ec2_sd_configs: [ - &lt;ec2_sd_config&gt; ... ]# OpenStack服务发现配置列表。openstack_sd_configs: [ - &lt;openstack_sd_config&gt; ... ]# 文件服务发现配置列表。file_sd_configs: [ - &lt;file_sd_config&gt; ... ]# GCE服务发现配置列表。gce_sd_configs: [ - &lt;gce_sd_config&gt; ... ]# Kubernetes服务发现配置列表。kubernetes_sd_configs: [ - &lt;kubernetes_sd_config&gt; ... ]# Marathon服务发现配置列表。marathon_sd_configs: [ - &lt;marathon_sd_config&gt; ... ]# AirBnB的神经服务发现配置列表。nerve_sd_configs: [ - &lt;nerve_sd_config&gt; ... ]# Zookeeper Serverset服务发现配置列表。serverset_sd_configs: [ - &lt;serverset_sd_config&gt; ... ]# Triton服务发现配置列表。triton_sd_configs: [ - &lt;triton_sd_config&gt; ... ]# 此job的标记静态配置目标列表。static_configs: [ - &lt;static_config&gt; ... ]# 目标重新标记配置列表。relabel_configs: [ - &lt;relabel_config&gt; ... ]# 度量标准重新配置列表。metric_relabel_configs: [ - &lt;relabel_config&gt; ... ]# 对每个将被接受的样本数量的每次抓取限制。# 如果在度量重新标记后存在超过此数量的样本，则整个抓取将被视为失败。 0表示没有限制。[ sample_limit: &lt;int&gt; | default = 0 ] rule_files记录规则,编写的记录规则是定义一些常用计算规则.这些规则会存储到数据中.告警的警报规则文件需要在这里引入. 12rule_files: [ - &lt;filepath_glob&gt; ... ] alertingAlertmanager相关配置 12345alerting: alert_relabel_configs: [ - &lt;relabel_config&gt; ... ] alertmanagers: [ - &lt;alertmanager_config&gt; ... ] &lt;alertmanager_config&gt;alertmanager_config部分指定Prometheus服务器向其发送警报的Alertmanager实例。 它还提供参数以配置如何与这些Alertmanagers进行通信。Alertmanagers可以通过static_configs参数静态配置，也可以使用其中一种支持的服务发现机制动态发现。此外，relabel_configs允许从发现的实体中选择Alertmanagers，并对使用的API路径提供高级修改，该路径通过alerts_path标签公开。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 推送警报时按目标Alertmanager超时。[ timeout: &lt;duration&gt; | default = 10s ]# 将推送HTTP路径警报的前缀。[ path_prefix: &lt;path&gt; | default = / ]# 配置用于请求的协议方案。[ scheme: &lt;scheme&gt; | default = http ]# 使用配置的用户名和密码在每个请求上设置`Authorization`标头。 password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;string&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个请求上设置“Authorization”标头。 它与`bearer_token_file`互斥。[ bearer_token: &lt;string&gt; ]# 使用配置的承载令牌在每个请求上设置“Authorization”标头。 它与`bearer_token`互斥。[ bearer_token_file: /path/to/bearer/token/file ]# 配置scrape请求的TLS设置。tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL。[ proxy_url: &lt;string&gt; ]# Azure服务发现配置列表。azure_sd_configs: [ - &lt;azure_sd_config&gt; ... ]# Consul服务发现配置列表。consul_sd_configs: [ - &lt;consul_sd_config&gt; ... ]# DNS服务发现配置列表。dns_sd_configs: [ - &lt;dns_sd_config&gt; ... ]# ECS服务发现配置列表。ec2_sd_configs: [ - &lt;ec2_sd_config&gt; ... ]# 文件服务发现配置列表。file_sd_configs: [ - &lt;file_sd_config&gt; ... ]# GCE服务发现配置列表。gce_sd_configs: [ - &lt;gce_sd_config&gt; ... ]# K8S服务发现配置列表。kubernetes_sd_configs: [ - &lt;kubernetes_sd_config&gt; ... ]# Marathon服务发现配置列表。marathon_sd_configs: [ - &lt;marathon_sd_config&gt; ... ]# AirBnB's Nerve 服务发现配置列表。nerve_sd_configs: [ - &lt;nerve_sd_config&gt; ... ]# Zookepper服务发现配置列表。serverset_sd_configs: [ - &lt;serverset_sd_config&gt; ... ]# Triton服务发现配置列表。triton_sd_configs: [ - &lt;triton_sd_config&gt; ... ]# 标记为静态配置的Alertmanagers列表。static_configs: [ - &lt;static_config&gt; ... ]# Alertmanager重新配置列表。relabel_configs: [ - &lt;relabel_config&gt; ... ] remote_write云端写入数据 &lt;remote_write&gt;write_relabel_configs是在将样本发送到远程端点之前应用于样本的重新标记。 在外部标签之后应用写入重新标记。 这可用于限制发送的样本。 有一个如何使用此功能的小型演示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 要发送样本的端点的URL.url: &lt;string&gt;# 对远程写端点的请求超时。[ remote_timeout: &lt;duration&gt; | default = 30s ]# 远程写入重新标记配置列表。write_relabel_configs: [ - &lt;relabel_config&gt; ... ]# 使用配置的用户名和密码在每个远程写请求上设置`Authorization`标头.password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;string&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_token_file`互斥。[ bearer_token: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_token`互斥。[ bearer_token_file: /path/to/bearer/token/file ]# 配置远程写入请求的TLS设置。tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL。[ proxy_url: &lt;string&gt; ]# 配置用于写入远程存储的队列。queue_config: # 在我们开始删除之前每个分片缓冲的样本数。 [ capacity: &lt;int&gt; | default = 10000 ] # 最大分片数，即并发数。 [ max_shards: &lt;int&gt; | default = 1000 ] # 最小分片数，即并发数。 [ min_shards: &lt;int&gt; | default = 1 ] # 每次发送的最大样本数。 [ max_samples_per_send: &lt;int&gt; | default = 100] # 样本在缓冲区中等待的最长时间。 [ batch_send_deadline: &lt;duration&gt; | default = 5s ] # 在可恢复错误上重试批处理的最大次数。 [ max_retries: &lt;int&gt; | default = 3 ] # 初始重试延迟。 每次重试都会加倍。 [ min_backoff: &lt;duration&gt; | default = 30ms ] # 最大重试延迟。 [ max_backoff: &lt;duration&gt; | default = 100ms ] remote_read云端读取数据 &lt;remote_read&gt; 12345678910111213141516171819202122232425262728293031# 要发送样本的端点的URL.url: &lt;string&gt;# 可选的匹配器列表，必须存在于选择器中以查询远程读取端点。required_matchers: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ]# 对远程读取端点的请求超时。[ remote_timeout: &lt;duration&gt; | default = 1m ]# 本地存储应该有完整的数据。[ read_recent: &lt;boolean&gt; | default = false ]# 使用配置的用户名和密码在每个远程写请求上设置`Authorization`标头.password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;string&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_toke_filen`互斥。[ bearer_token: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_token`互斥。[ bearer_token_file: /path/to/bearer/token/file ]# 配置远程写入请求的TLS设置。tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL。[ proxy_url: &lt;string&gt; ] relabel_configs用来重新打标记,修改标签. 请注意labels 的取名格式:标签label名称可以包含ASCII字母、数字和下划线。它们必须匹配正则表达式[a-zA-Z_][a-zA-Z0-9_]*。带有_下划线的标签名称被保留内部使用。 标签labels值包含任意的Unicode码。 &lt;relabel_configs&gt;Prometheus 重新标签允许在采集之前对任何目标及其标签进行修改 • 重命名标签名 • 删除标签 • 过滤目标 action：重新标签动作 replace：默认，通过regex匹配source_label的值，使用replacement来引用表达式匹配的分组 keep：删除regex与连接不匹配的目标 source_labels drop：删除regex与连接匹配的目标 source_labels labeldrop：删除regex匹配的标签 labelkeep：删除regex不匹配的标签 hashmod：设置target_label为modulus连接的哈希值source_labels labelmap：匹配regex所有标签名称。然后复制匹配标签的值进行分组，replacement分组引用（${1},${2},…）替代 12345678910111213141516171819202122relable_configs:# 源标签从现有标签中选择值。 它们的内容使用已配置的分隔符进行连接，并与已配置的正则表达式进行匹配，以进行替换，保留和删除操作。[ source_labels: '[' &lt;labelname&gt; [, ...] ']' ]# 分隔符放置在连接的源标签值之间。[ separator: &lt;string&gt; | default = ; ]# 在替换操作中将结果值写入的标签。# 替换操作是强制性的。 正则表达式捕获组可用。[ target_label: &lt;labelname&gt; ]# 与提取的值匹配的正则表达式。[ regex: &lt;regex&gt; | default = (.*) ]# 采用源标签值的散列的模数。[ modulus: &lt;uint64&gt; ]# 如果正则表达式匹配，则执行正则表达式替换的替换值。 正则表达式捕获组可用。[ replacement: &lt;string&gt; | default = $1 ]# 基于正则表达式匹配执行的操作。[ action: &lt;relabel_action&gt; | default = replace ]","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"}]},{"title":"curl: (3) Illegal characters found in URL","slug":"curl-3-Illegal-characters-found-in-URL","date":"2019-10-09T06:45:13.000Z","updated":"2020-04-14T06:55:05.118Z","comments":true,"path":"2019/10/09/curl-3-Illegal-characters-found-in-URL/","link":"","permalink":"http://blog.51ai.vip/2019/10/09/curl-3-Illegal-characters-found-in-URL/","excerpt":"","text":"curl: (3) Illegal characters found in URL昨天在服务器上执行一个脚本,在linux新建的sh,把本地编辑器的内容粘贴到文件里.结果执行的时候报错了. 问题就是 curl:(3)Illegal characters found in URL 看着一脸懵逼啊!~ google了一下,看到几个方法.其中一个我感觉还不错: 首先vi 进入sh脚本 vi XXX.sh :set ff? # 这里我现实的是 fileforma=dos 我这里显示是这个 :set fileformat=unix # 把fileforma 设置好 :wq 通过这个方式,可以解决这个问题,网上也有人提出其他方法把\\r\\n 手动替换\\n的. 参考:http://www.itbiancheng.com/linux/4885.html","categories":[{"name":"note","slug":"note","permalink":"http://blog.51ai.vip/categories/note/"}],"tags":[{"name":"curl","slug":"curl","permalink":"http://blog.51ai.vip/tags/curl/"}]},{"title":"yaml规则","slug":"YAML规则","date":"2019-09-24T02:20:31.000Z","updated":"2020-04-14T06:55:05.122Z","comments":true,"path":"2019/09/24/YAML规则/","link":"","permalink":"http://blog.51ai.vip/2019/09/24/YAML规则/","excerpt":"","text":"yml 语法最近经常配置一些服务，发现大部分都是yml类型文件。小记一下。 规则 大小写敏感 缩进表示层级 注释 # 结构：对象： ：符号 1name: admin 数组： - 符号 1234user: - name: admin - height: 178 - age: 30 字符串： 默认无引号，内部含有空格或特殊符号需要加’’ 12name: admindesc: 'he was cool' null： ~ 1value: ~ 层级依靠缩进： 12345job: - jobconfig: name: 'snmp-sw01' - target: - 192.168.1.88","categories":[{"name":"yaml","slug":"yaml","permalink":"http://blog.51ai.vip/categories/yaml/"}],"tags":[{"name":"yaml","slug":"yaml","permalink":"http://blog.51ai.vip/tags/yaml/"}]},{"title":"Grafana中文化","slug":"Grafana汉化","date":"2019-09-16T07:37:46.000Z","updated":"2020-04-14T06:55:05.110Z","comments":true,"path":"2019/09/16/Grafana汉化/","link":"","permalink":"http://blog.51ai.vip/2019/09/16/Grafana汉化/","excerpt":"","text":"可视化图表Grafana是一个通用的可视化工具。通过Grafana可以管理用户权限，数据分析，查看，导出，设置告警等。 仪表盘Dashboard通过数据源定义好可视化的数据来源之后，对于用户而言最重要的事情就是实现数据的可视化。 面板 PanelPanel是Grafana中最基本的可视化单元。每一种类型的面板都提供了相应的查询编辑器(Query Editor)，让用户可以从不同的数据源（如Prometheus）中查询出相应的监控数据，并且以可视化的方式展现。Grafana中所有的面板均以插件的形式进行使用，当前内置了5种类型的面板，分别是：Graph，Singlestat，Heatmap, Dashlist，Table以及Text。 翻译工作上面简单介绍了一下工具，主要是让我们方便查看监控的数据。这里我还是没有更深入的去研究公式等图形的设置。这里先主要写一下翻译方面的工作。 公司也考虑展示内容为中文化比较好，这里Grafana没有提供语言包的方式来处理多语言问题。在我查看代码过程中，发现工具后台是在GO里面写死的很多导航，返回值等数据。前台是在页面上直接写的很多内容。所以我个人认为无法使用语言包来直接处理多语言问题。那就只好自己来搞定了。 翻译的内容更具代码查看，主要分为两大部分： 后端： go文件，主要内容在/pkg 目录下。 前端： 1. 系统页面 2. 插件页面 这些在/public 目录下 准备工作首先git clone Grafana库git clone https://github.com/chenweil/grafana.git 之后我们根据自己翻译的版本来检出自己的项目。这里我们使用的v6.3.4 ，官方版本中可以查看到tag v6.3.4,并重命名自己的分支为6.3.4-chs：git checkout -b 6.3.4-chs 通过 git branch 命令查看自己处于哪个分支上。这里如果你不是很熟悉git命令行，可以使用sourcetree工具操作，相对来说点点鼠标就可以搞定了。 我们在自己创建的分支就可以来处理我们的工作了。 前端调试环境需要 npm，nodejs，yarn 终端执行命令yarn install --pure-lockfile 初始化. 如果没有报错的情况,证明ok. 出现错误请先处理问题.开启调试环境时候，是开启前端的热加载来协助我们调试。这里安装完三个环境可能在执行 yarn start 时报错，这里如果你是在windows上，需要再安装一下sass.(根据报错来看问题，我这里遇到缺少sass问题) 当我们yarn start 执行后，等待一段时间，build at 时间证明准备工作已完成，下面就需要我们在调试模式下测试了。 还需要一个调试的Grafana服务程序，这里是windows环境，所以直接从官方下载了zip包，执行bin下的grafana-server.exe 来启动服务。需要再conf文件夹修改一下public前端资源的配置，如果不修改那么你翻译的信息是看不到的，服务会直接读取的当前的public，我们这需要读取翻译的public文件位置。 配置在windows服务程序的 /conf/defaults.ini修改内容： 12app_mode = development # 开发模式static_root_path = D:\\grafana\\public #这里配置到git拉取得位置的public 按照正常的操作 是需要开启webpack-dev-server我这里没有这么设置，直接利用3000端口调试的。（当我们yarn start 后，通过修改页面可以看修改的内容。） 翻译前端文件前面环境已经搭建好之后，我们通过修改页面文件展示内容来翻译。例如翻译登陆页面：/public/app/partials/login.html把对应的英文改为中文，保存后webpack会处理。处理完成刷新页面可以看到结果。 前端翻译文件不止html，还有ts，tsx等文件。这里如果不知道具体文件可以在public文件夹下，通过全局搜索页面的单词等信息定位到文件。我没有翻译带有test 的测试文件。 最后我们把需要的文件都翻译之后，通过yarn build 生成文件。这些文件都存在生成的目录/public/build中。把这些文件覆盖到自己搭建的项目中完成汉文。建议把整体public目录替换。重启服务既可以看到中文版的页面了。 后端环境后端是用GO写的。后端我没有调试，不想前端那样可以边调边看。我的办法就是全部改完，build程序，启动查看后端翻译的结果。所需，本人是在windows10下处理的，需要gcc，go。 翻译后端文件文件所在位置： /pkg/ 首页我们的导航，二级菜单这些不是前端控制的，这些是在 /pkg/api/index.go 其余还有很多文件，内容包含：html数据，返回值信息，debug信息等。如果你前端翻译完成，那么后端对你来说也是很轻松的。 请注意一些参数或者判断不要给翻译了 当翻译完成后，需要build。首先到项目根目录，这里可以看到 build.go 文件。用这个来生成后端程序。 windows下可以build .exe程序。 时间很短，便于我们调试。 build前，先steup一下，执行 go run build.go setup。 12345$ go run build.go setupVersion: 6.3.4, Linux Version: 6.3.4, Package Iteration: 1568870230go install -v ./pkg/cmd/grafana-servergithub.com/grafana/grafana/pkg/apigithub.com/grafana/grafana/pkg/cmd/grafana-server 如果没有报错，那么证明是可以执行build了。这里可能你会遇到一些错误，出现错误先解决错误再重新执行 go run build.go setup，直到没有错误。我遇到一下错误： error loading module requirements这个问题一查一大把，原因就是你需要的模块下载不到，地址被墙。解决方式： 其中一种：go.mod 添加replace() 替换地址。下面并非全部用到，我是偷懒全粘上。 123456789101112131415161718192021222324252627282930313233343536replace ( golang.org/x/build =&gt; github.com/golang/build v0.0.0-20190416225751-b5f252a0a7dd golang.org/x/crypto =&gt; github.com/golang/crypto v0.0.0-20190411191339-88737f569e3a golang.org/x/exp =&gt; github.com/golang/exp v0.0.0-20190413192849-7f338f571082 golang.org/x/image =&gt; github.com/golang/image v0.0.0-20190417020941-4e30a6eb7d9a golang.org/x/lint =&gt; github.com/golang/lint v0.0.0-20190409202823-959b441ac422 golang.org/x/mobile =&gt; github.com/golang/mobile v0.0.0-20190415191353-3e0bab5405d6 golang.org/x/net =&gt; github.com/golang/net v0.0.0-20190415214537-1da14a5a36f2 golang.org/x/oauth2 =&gt; github.com/golang/oauth2 v0.0.0-20190402181905-9f3314589c9a golang.org/x/perf =&gt; github.com/golang/perf v0.0.0-20190312170614-0655857e383f golang.org/x/sync =&gt; github.com/golang/sync v0.0.0-20190412183630-56d357773e84 golang.org/x/sys =&gt; github.com/golang/sys v0.0.0-20190416152802-12500544f89f golang.org/x/text =&gt; github.com/golang/text v0.3.0 golang.org/x/time =&gt; github.com/golang/time v0.0.0-20190308202827-9d24e82272b4 golang.org/x/tools =&gt; github.com/golang/tools v0.0.0-20190417005754-4ca4b55e2050 golang.org/x/xerrors =&gt; github.com/golang/xerrors v0.0.0-20190410155217-1f06c39b4373 google.golang.org/api =&gt; github.com/googleapis/google-api-go-client v0.3.2 google.golang.org/appengine =&gt; github.com/golang/appengine v1.5.0 google.golang.org/genproto =&gt; github.com/google/go-genproto v0.0.0-20190415143225-d1146b9035b9 google.golang.org/grpc =&gt; github.com/grpc/grpc-go v1.20.0 gopkg.in/asn1-ber.v1 =&gt; github.com/go-asn1-ber/asn1-ber v0.0.0-20181015200546-f715ec2f112d gopkg.in/fsnotify.v1 =&gt; github.com/Jwsonic/recinotify v0.0.0-20151201212458-7389700f1b43 gopkg.in/gorethink/gorethink.v4 =&gt; github.com/rethinkdb/rethinkdb-go v4.0.0+incompatible gopkg.in/ini.v1 =&gt; github.com/go-ini/ini v1.42.0 gopkg.in/src-d/go-billy.v4 =&gt; github.com/src-d/go-billy v4.2.0+incompatible gopkg.in/src-d/go-git-fixtures.v3 =&gt; github.com/src-d/go-git-fixtures v3.4.0+incompatible gopkg.in/yaml.v2 =&gt; github.com/go-yaml/yaml v2.1.0+incompatible k8s.io/api =&gt; github.com/kubernetes/api v0.0.0-20190416052506-9eb4726e83e4 k8s.io/apimachinery =&gt; github.com/kubernetes/apimachinery v0.0.0-20190416092415-3370b4aef5d6 k8s.io/client-go =&gt; github.com/kubernetes/client-go v11.0.0+incompatible k8s.io/klog =&gt; github.com/simonpasquier/klog-gokit v0.1.0 k8s.io/kube-openapi =&gt; github.com/kubernetes/kube-openapi v0.0.0-20190401085232-94e1e7b7574c k8s.io/utils =&gt; github.com/kubernetes/utils v0.0.0-20190308190857-21c4ce38f2a7 sigs.k8s.io/yaml =&gt; github.com/kubernetes-sigs/yaml v1.1.0 go.uber.org/atomic =&gt; github.com/uber-go/atomic v1.3.2) 还有方法是通过设置Module GOPROXY代理。大概意思就是当构建或运行你的应用时,Go 会通过 GOPROXY 获取依赖。 这个我没测试，有兴趣自行查阅。 exec: “gcc”: executable file not found in %PATH% 这个问题是我们环境没有gcc，这个玩意儿需要下载一个软件MinGW。 此地址提供的压缩包文件。解压可以使用，此网站也提供下载器安装方式。这网站下载贼慢 解压之后设置环境变量，当前解压完路径是： C:\\MinGW\\mingw64 在环境变量添加此目录。 cmd 测试 gcc -v 有信息即ok。 没有问题 执行 go run build.go build完成后，就可以得到bin文件，位置在 /bin/windows-amd64/ ， 里面有grafana-server.exe 程序。 在测试前端时候，用的那个windwos程序可以下岗了，把build之后的bin程序+md5文件一起复制到这目录里。如果你不放心提前先备份一份。 之后按照测试前端那样，打开服务，访问3000，查看自己汉化后端的成果吧。 生成docker镜像在windows可以直接加载public,bin生成之后替换原bin程序. linux是类似,build出来的bin,需要在linux上build. 我们这里主要是想利用docker. 还没完，我们刚才只是测试一下自己汉化的后端是否可以。如果测试完都可以之后，我们还是要把它build成镜像，利用docker来运行服务。如果你不想用docker，就考虑在build为linux程序。 生成docker镜像可以分为两种，一种是你所在linux/amd64中生成的镜像，另一种是通用的镜像。 第一种: linux系统上省事一点go run build.go setup go run build.go build 第二种通用镜像：make build-docker-full 或者 docker build -t grafana/grafana:dev . 这里我没有成功build出来镜象,我在linux上尝试了几次,两种方法build出来的镜象启动提示 run.sh 权限存在问题,如果我＋x run.sh之后,提示一些其他错误. 那镜象我是通过commit来完成制作的.通过汉化的文件cp到容器中在commit成一个镜象. 如果想用我的镜象,请点击这里. 到此终于结束啦。","categories":[{"name":"可视化图表","slug":"可视化图表","permalink":"http://blog.51ai.vip/categories/可视化图表/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"http://blog.51ai.vip/tags/Grafana/"}]},{"title":"Centos7安装nodejs","slug":"Centos7安装nodejs","date":"2019-09-02T02:15:01.000Z","updated":"2020-04-14T06:55:05.106Z","comments":true,"path":"2019/09/02/Centos7安装nodejs/","link":"","permalink":"http://blog.51ai.vip/2019/09/02/Centos7安装nodejs/","excerpt":"","text":"安装nodejs下载官方node的tar包:https://nodejs.org/en/download/ wget https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz 解压下载文件tar -xvf node-v10.16.3-linux-x64.tar.xz 部署bin这里下载位置为家里面 ~/ ln -s ~/node-v10.16.3-linux-x64/bin/node /usr/bin/node ln -s ~/node-v10.16.3-linux-x64/bin/npm /usr/bin/npm 一个是node 另一个是npm 验证node -vnpm -v","categories":[{"name":"Centos","slug":"Centos","permalink":"http://blog.51ai.vip/categories/Centos/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://blog.51ai.vip/tags/nodejs/"}]},{"title":"Prometheus-snmp_export部署","slug":"Prometheus-snmp-export部署","date":"2019-08-29T02:06:01.000Z","updated":"2020-04-14T06:55:05.114Z","comments":true,"path":"2019/08/29/Prometheus-snmp-export部署/","link":"","permalink":"http://blog.51ai.vip/2019/08/29/Prometheus-snmp-export部署/","excerpt":"","text":"SNMPSNMP(simple network management protocol)是因特网架构委员会IAB定义的一个应用层协议。SNMP广泛用于管理和监控网络设备，大多数专业的网络设备都有SNMP agent代理，这些代理被激活和配置后用于和SNMP管理 NMS(network management system)网络管理系统通信。 目的通过snmp_export,获取设备信息. 准备系统: centos7,docker19.之前已经安装好 Prometheus 此处目标设备是华为交换机 s2700 部署snmp_expoersnmp.yml 配置文件不是自己定义的,是通过注册生成或下载的.这里我通过github下载配置文件. snmp.yml 配置snmp_export 配置文件 snmp.yml 123version: 2auth: community: **交换机设置的团体名** 查找到if_mib 再此段结尾中加入 上面的配置(大概行数6199). 部署snmp_expor123docker run -d --restart always \\-v /home/along/snmp.yml:/etc/snmp_exporter/snmp.yml \\-p 9116:9116 --name snmp-exporter prom/snmp-exporter \\ --config.file=\"/etc/snmp_exporter/snmp.yml\" 配置华为s2700交换机自行查阅文档.懒得写了. 验证服务访问 http://IP:9116/metrics 能返回数据,snmp_export服务正常. 测试是否能获取到目标设备的数据:访问 http://IP:9116/snmp?target=DEVIP能获取到数据,配置成功. 注意防火墙 把需要的端口加入规则中,不然访问不到排查绕弯路 配置promthues修改 promthues.yml文件. 添加一个新的job. 1234567891011121314151617181920212223242526272829303132- job_name: snmp honor_timestamps: true params: module: - if_mib scrape_interval: 15s scrape_timeout: 10s metrics_path: /snmp scheme: http static_configs: - targets: - 172.16.23.253 labels: tag: huawei-switch-s2700 relabel_configs: - source_labels: [__address__] separator: ; regex: (.*) target_label: __param_target replacement: $1 action: replace - source_labels: [__param_target] separator: ; regex: (.*) target_label: instance replacement: $1 action: replace - separator: ; regex: (.*) target_label: __address__ replacement: 172.16.23.12:9116 action: replace 之前部署prometheus 有一个参数是为了热加载配置的.这里需要reload一下配置,curl -X POST http://IP:9090/-/reload,如果你没有就重启服务吧. 验证 Prometheus配置访问 http://IP:9090/点击 Status-&gt;Target 可以看到监控的节点,之前我们是有一个,现在是两个节点了. 有数据之后,就可以在grafana中展示设备的数据了. 参考https://github.com/prometheus/snmp_exporter https://prometheus.io/docs/instrumenting/exporters/ http://owelinux.github.io/owelinux.github.io/2018/07/25/article8-linux-prometheus/","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"SNMP","slug":"SNMP","permalink":"http://blog.51ai.vip/tags/SNMP/"}]},{"title":"Prometheus+Grafana安装搭建","slug":"Prometheus-Grafana安装搭建","date":"2019-08-28T08:23:05.000Z","updated":"2020-12-10T07:12:47.399Z","comments":true,"path":"2019/08/28/Prometheus-Grafana安装搭建/","link":"","permalink":"http://blog.51ai.vip/2019/08/28/Prometheus-Grafana安装搭建/","excerpt":"","text":"介绍 Prometheus是由SoundCloud开发的开源监控报警系统和时序列数据库(TSDB)。Prometheus使用Go语言开发，是Google BorgMon监控系统的开源版本。 2016年由Google发起Linux基金会旗下的原生云基金会(Cloud Native Computing Foundation), 将Prometheus纳入其下第二大开源项目。Prometheus目前在开源社区相当活跃。 Prometheus和Heapster(Heapster是K8S的一个子项目，用于获取集群的性能数据。)相比功能更完善、更全面。Prometheus性能也足够支撑上万台规模的集群。 Prometheus的特点: 多维度数据模型。 灵活的查询语言。 不依赖分布式存储，单个服务器节点是自主的。 通过基于HTTP的pull方式采集时序数据。 可以通过中间网关进行时序列数据推送。 通过服务发现或者静态配置来发现目标服务对象。 支持多种多样的图表和界面展示，比如Grafana等。 架构图 Prometheus服务大致过程： Prometheus 定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。 Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。 Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。 PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 Prometheus 支持通过SNMP协议获取mertics数据.通过配置job,利用snmp_export读取设备监控信息. 指标(Metric)类型 Counter 计数器,从数据0开始累计计算. 理想状态会永远增长. 累计计算请求次数等 Gauges 瞬时状态的值. 可以任意变化的数值，适用 CPU 使用率 温度等 Histogram 对一段时间范围内数据进行采样，并对所有数值求和与统计数量、柱状图. 某个时间对某个度量值，分组，一段时间http相应大小，请求耗时的时间。 Summary 同样产生多个指标，分别带有后缀_bucket(仅histogram)、_sum、_count Histogram和Summary都可以获取分位数。通过Histogram获得分位数，要将直方图指标数据收集prometheus中， 然后用prometheus的查询函数histogram_quantile()计算出来。 Summary则是在应用程序中直接计算出了分位数。Histograms and summaries中阐述了两者的区别，特别是Summary的的分位数不能被聚合。注意，这个不能聚合不是说功能上不支持，而是说对分位数做聚合操作通常是没有意义的。LatencyTipOfTheDay: You can’t average percentiles. Period中对“分位数”不能被相加平均的做了很详细的说明：分位数本身是用来切分数据的，它们的平均数没有同样的分位效果。 主要我们监控用到最上面两种,下面两种类型目前我没有接触,上面这段文字与介绍引用自lijiaocn 安装Prometheus本次搭建利用docker方式.整体搭建完成需要两个容器.暂不配置告警相关,只做监控数据 前提 搭建位置: /home/aLong/prometheus/ 环境:docker19.03.1 需要指定版本请查阅官方文档. 系统:centos7 准备工作Prometheus的配置文件: prometheus.yml我们建立在搭建位置的根下: touch prometheus.yml在配置文件中加入测试演示配置 1234567891011121314global: scrape_interval: 15s scrape_timeout: 10s evaluation_interval: 15sscrape_configs:- job_name: prometheus honor_timestamps: true scrape_interval: 5s scrape_timeout: 3s metrics_path: /metrics scheme: http static_configs: - targets: - localhost:9090 注意配置文件的格式为yaml,语法问题请参考这里. 安装与运行 通过docker 启动 prometheus. 123456docker run -d -p 9090:9090 \\ -v /home/along/prometheus.yml:/etc/prometheus/prometheus.yml \\ --name prometheus \\ prom/prometheus \\ --config.file=/etc/prometheus/prometheus.yml \\ --web.enable-lifecycle –web.enable-lifecycle 启用远程热加载配置文件curl -X POST http://IP:9090/-/reload 注意这里docker热加载存在一个问题,上面挂在文件为/home/along/prometheus.yml 如果直接编辑此文件会改变文件的inode, 热加载不会成功. 解决办法: 我们不在挂在配置文件上做修改,复制一份,通过冲顶下方式到prometheus.yml上面 例如: cp /home/along/prometheus.yml /home/along/prom-edit.yml vi /home/along/prom-edit.ym cat /home/along/prom-edit.ym &gt; /home/along/prometheus.yml 此时 curl -X POST http://IP:9090/-/reload 会成功加载. 验证服务访问 http://IP:9090 会进入简单webUI界面中.这是prometheus的web界面. 里面看到一些信息和监控数据.可以展示图表. 点击 Status-&gt;Target 可以看到监控的设备信息. 访问http://IP:9090/metrics 可以看到监控数据. 到这里,Prometheus已经安装成功,并监测到本机数据. Grafana安装 Grafana是用于可视化大型测量数据的开源程序，它提供了强大和优雅的方式去创建、共享、浏览数据。Dashboard中显示了你不同metric数据源中的数据。Grafana最常用于因特网基础设施和应用分析，但在其他领域也有用到，比如：工业传感器、家庭自动化、过程控制等等。Grafana支持热插拔控制面板和可扩展的数据源，目前已经支持Graphite、InfluxDB、OpenTSDB、Elasticsearch、Prometheus等 官方：docker run -d -p 3000:3000 --name grafana grafana/grafana 汉化：docker run -d -p 3000:3000 --name grafana chenwl2016/grafana-chs:0.1.5 执行后,通过http:IP:3000 访问grafana.缺省账号密码admin 进入后会有首页的一个引导.添加数据源,选择prometheus.之后可以看到默认的模板上会有数据. 通过官网查询模板插件.导入到系统中.自定义模板选择需要的数据来展示,这里我还没玩6,暂不多说了. 参考https://grafana.com/docs/https://prometheus.io/docs/introduction/overview/https://www.hi-linux.com/posts/25047.html#%E5%AE%89%E8%A3%85prometheushttps://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2018/08/03/prometheus-usage.html#metric%E7%B1%BB%E5%9E%8B","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"http://blog.51ai.vip/tags/Grafana/"},{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"}]},{"title":"Centos5不升级内核更新","slug":"Centos5不升级内核更新","date":"2019-08-23T09:37:03.000Z","updated":"2021-05-06T07:08:32.783Z","comments":true,"path":"2019/08/23/Centos5不升级内核更新/","link":"","permalink":"http://blog.51ai.vip/2019/08/23/Centos5不升级内核更新/","excerpt":"","text":"前提公司需要环境Centos5, 又不能升级内核. 查了一下 大概是 需要 yum –exclude=kernel* update 或者修改 yum.conf 测试一下 出现一个问题:123456Loaded plugins: fastestmirror, securityLoading mirror speeds from cached hostfileYumRepo Error: All mirror URLs are not using ftp, http[s] or file. Eg. Invalid release/removing mirrorlist with no valid mirrors: /var/cache/yum/base/mirrorlist.txtError: Cannot find a valid baseurl for repo: base 根据查询到的信息是,没有正常的源. 解决问题 根据网上的源地址 修改一下:位置: /etc/yum.repos.d/CentOS-Base.repo 修改内容:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[base]name=CentOS-5.11 - Base#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=osbaseurl=http://vault.centos.org/5.11/os/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#released updates[updates]name=CentOS-5.11 - Updates#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=updatesbaseurl=http://vault.centos.org/5.11/updates/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#packages used/produced in the build but not released[addons]name=CentOS-5.11 - Addons#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=addonsbaseurl=http://vault.centos.org/5.11/addons/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#additional packages that may be useful[extras]name=CentOS-5.11 - Extras#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=extrasbaseurl=http://vault.centos.org/5.11/extras/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#additional packages that extend functionality of existing packages[centosplus]name=CentOS-5.11 - Plus#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=centosplusbaseurl=http://vault.centos.org/5.11/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#contrib - packages by Centos Users[contrib]name=CentOS-5.11 - Contrib#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=contribbaseurl=http://vault.centos.org/5.11/contrib/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5 之后 再使用上面的yum 去更新,发现yum 语句是有问题的. 正确的命令是: yum --exclude=kernel\\* update 或者 yum -x &#39;kernel*&#39; update 确认是否生效首先 yum update 内容可以看到 安装内容中 包含 ‘kernel’ 信息. 之后 执行上句命令后,可以看到 更新信息里没有 ‘kernel’ . 最后可以确定,这个方案是有效的.","categories":[],"tags":[]},{"title":"Centos5不升级内核更新","slug":"Centos5不升级内核更新 2","date":"2019-08-23T09:37:03.000Z","updated":"2021-05-06T07:04:00.124Z","comments":true,"path":"2019/08/23/Centos5不升级内核更新 2/","link":"","permalink":"http://blog.51ai.vip/2019/08/23/Centos5不升级内核更新 2/","excerpt":"","text":"前提公司需要环境Centos5, 又不能升级内核. 查了一下 大概是 需要 yum –exclude=kernel* update 或者修改 yum.conf 测试一下 出现一个问题:123456Loaded plugins: fastestmirror, securityLoading mirror speeds from cached hostfileYumRepo Error: All mirror URLs are not using ftp, http[s] or file. Eg. Invalid release/removing mirrorlist with no valid mirrors: /var/cache/yum/base/mirrorlist.txtError: Cannot find a valid baseurl for repo: base 根据查询到的信息是,没有正常的源. 解决问题 根据网上的源地址 修改一下:位置: /etc/yum.repos.d/CentOS-Base.repo 修改内容:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[base]name=CentOS-5.11 - Base#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=osbaseurl=http://vault.centos.org/5.11/os/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#released updates[updates]name=CentOS-5.11 - Updates#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=updatesbaseurl=http://vault.centos.org/5.11/updates/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#packages used/produced in the build but not released[addons]name=CentOS-5.11 - Addons#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=addonsbaseurl=http://vault.centos.org/5.11/addons/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#additional packages that may be useful[extras]name=CentOS-5.11 - Extras#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=extrasbaseurl=http://vault.centos.org/5.11/extras/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#additional packages that extend functionality of existing packages[centosplus]name=CentOS-5.11 - Plus#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=centosplusbaseurl=http://vault.centos.org/5.11/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#contrib - packages by Centos Users[contrib]name=CentOS-5.11 - Contrib#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=contribbaseurl=http://vault.centos.org/5.11/contrib/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5 之后 再使用上面的yum 去更新,发现yum 语句是有问题的. 正确的命令是: yum --exclude=kernel\\* update 或者 yum -x &#39;kernel*&#39; update 确认是否生效首先 yum update 内容可以看到 安装内容中 包含 ‘kernel’ 信息. 之后 执行上句命令后,可以看到 更新信息里没有 ‘kernel’ . 最后可以确定,这个方案是有效的.","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos5","slug":"Centos5","permalink":"http://blog.51ai.vip/tags/Centos5/"}]},{"title":"Laradock安装与使用","slug":"Laradock安装与使用","date":"2019-08-15T02:01:03.000Z","updated":"2020-04-14T06:55:05.111Z","comments":true,"path":"2019/08/15/Laradock安装与使用/","link":"","permalink":"http://blog.51ai.vip/2019/08/15/Laradock安装与使用/","excerpt":"","text":"Laradock 安装与使用官网 GitHub: https://github.com/laradock/laradock 要求 Git Docker &gt;= 17.12 项目的位置 已有项目情况: git submodule add https://github.com/Laradock/laradock.git 克隆到项目根目录. 结构 : project-a laradock-a project-b laradock-b 没有项目情况: git clone https://github.com/laradock/laradock.git 克隆后,在同级部署项目. laradock project-x project-y 启动环境clone下来还没有生成. 进入laradock目录,编辑Web服务器站点配置. cp env-exalpme .env环境是laradock环境,里面可以对相应的版本,配置进行修改.例如指定mysql版本为5.7 ,vim .env ,搜索到mysql部分, 修改MYSQL_VERSION=5.7.26 保存退出.(这里还没生成容器前可以统一配置好需要的环境,再生成容器.) 例如我们需要启动环境需要 mysql,redis,nginx. 执行 docker-compose up -d nginx mysql redis 经过漫长等待后,可以得到我们想要的环境,通过 docker ps 或者 docker-compose ps 查看容器. 如果先生成容器,在之后编辑环境时,需要停掉容器,修改完 build之后 再start 容器.例如修改nginx: docker-compose stop nginx 修改.env 或者 nginx conf docker-compose build nginx (完全重建,加参数: –no-cache) docker-compose start nginx Nginx 配置项目我们再laradock中,进入nginx/sites/ 下.复制laravel.conf.example 命名为我们的项目. cp laravel.conf.example Myblog.conf 我们在Myblog.conf 配置nginx 具体信息.这里与配置Vhost一样的操作. 修改完成后,需要build nginx(重建nginx容器). 项目配置数据库laravel项目, .env 中 此项需要改为DB_HOST=mysql,其他参数按照容器mysql配置账号密码等.Redis 修改类似. 项目执行php artisan 方式在laravel 需要执行 php artisan命令时,我们进入到workspace容器, docker-compose exec workspace bash 进入workkspace后,就可以像以前一样进入项目目录中可以执行. 也可以通过开启ssh.连接workspace 执行. 关闭所有正在运行的容器docker-compose stop 删除所有现有容器docker-compose down 其他内容请详见手册吧","categories":[{"name":"Laravel5","slug":"Laravel5","permalink":"http://blog.51ai.vip/categories/Laravel5/"}],"tags":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.51ai.vip/tags/Laravel/"},{"name":"docker","slug":"docker","permalink":"http://blog.51ai.vip/tags/docker/"}]},{"title":"SwitchHosts管理编辑hosts工具","slug":"SwitchHosts管理编辑hosts工具","date":"2019-08-14T01:41:55.000Z","updated":"2020-04-14T06:55:05.117Z","comments":true,"path":"2019/08/14/SwitchHosts管理编辑hosts工具/","link":"","permalink":"http://blog.51ai.vip/2019/08/14/SwitchHosts管理编辑hosts工具/","excerpt":"","text":"管理Hosts工具 SwitchHosts地址: SwitchHosts 开发工程中,针对不同项目设置不同的域名. 办法很多,例如直接编辑hosts文件,通过环境工具提供的功能设置等. 现在要安利一款便捷实用的工具. SwitchHosts!! 为什么,首先这工具是多平台支持的,我们可以在不同系统中使用.如果之前是靠编辑hosts文件的话,那不同的hosts位置还需要记忆一下,当然这也算不了什么难事. 他的有点不在于能简单编辑hosts文件,也有之前的记录,还可以通过url来读取云端的hosts信息.导入导出功能等. 总之又可以偷懒了. 主界面: 我们可以编辑不同host 分组,使用时打开开关按钮即可使用.示例中使用的My hosts中的配置 配置界面: 支持中文,主题黑白两色.","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.51ai.vip/categories/Tools/"}],"tags":[{"name":"hosts","slug":"hosts","permalink":"http://blog.51ai.vip/tags/hosts/"}]},{"title":"VMware安装MacOS系统","slug":"VMware安装MacOS系统","date":"2019-08-12T03:29:38.000Z","updated":"2020-04-14T06:55:05.118Z","comments":true,"path":"2019/08/12/VMware安装MacOS系统/","link":"","permalink":"http://blog.51ai.vip/2019/08/12/VMware安装MacOS系统/","excerpt":"","text":"虚拟机安装 macOS准备工作: VM关闭进程,利用macOS Unlocker修改VM使其能安装macOS系统, 执行程序 win-install.cmd 使用管理员权限运行脚本. 准备好macOS镜象. 利用VM创建虚机,系统类型选择macOS,版本号选择与下载的镜象版本相同. 装系统: 启动虚拟机,并通过cdrom加载镜象. 首次安装需要先利用系统内硬盘工具格式化硬盘,之后利用安装工具进行系统安装. 异常问题: 开启虚拟机弹出错误:vcpu-0 错误. 修改虚机镜象文件.vmx 在smc.present = “TRUE”下面插入一行代码: smc.version = 0 不能正常登陆APPID 需要修改虚拟机,利用Chameleon Wizard 伪造设备信息. 保存 生成的信息 去修改镜象所在文件下的.vmx 修改 board-id.reflectHost = “TRUE” 为FALSE,并在下面插入需要的伪造设备信息例子: board-id = “Mac-94245B3640C91C81”hw.model.reflectHost = “FALSE”hw.model = “MacBook Pro”serialNumber.reflectHost = “FALSE”serialNumber = “C02JJ8B3DH2G”smbios.reflectHost = “FALSE” 这段信息中的board-id 与 serialNumber 不要与例子的相同.其他可以参考.最后保存,重启. 重启之后尝试是否可以登陆市场.","categories":[{"name":"MacOs","slug":"MacOs","permalink":"http://blog.51ai.vip/categories/MacOs/"}],"tags":[{"name":"VM","slug":"VM","permalink":"http://blog.51ai.vip/tags/VM/"},{"name":"MacOs","slug":"MacOs","permalink":"http://blog.51ai.vip/tags/MacOs/"}]},{"title":"数据库迁移","slug":"Laravel5数据库迁移","date":"2019-07-26T06:30:25.000Z","updated":"2020-04-14T06:55:05.112Z","comments":true,"path":"2019/07/26/Laravel5数据库迁移/","link":"","permalink":"http://blog.51ai.vip/2019/07/26/Laravel5数据库迁移/","excerpt":"","text":"Laravel5 数据库迁移笔记 创建迁移文件 命令: make:migration 举例: php artisan make:migration create_users_table --create=users 生成位置: 项目/database/migrations/下 文件名已时间开头,后面是自己创建迁移文件名字. –creat 指定数据库中表的名字 编辑迁移文件 打开迁移文件:","categories":[{"name":"Laravel5","slug":"Laravel5","permalink":"http://blog.51ai.vip/categories/Laravel5/"}],"tags":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.51ai.vip/tags/Laravel/"}]},{"title":"Composer笔记","slug":"Composer笔记","date":"2019-07-15T09:24:45.000Z","updated":"2020-04-14T06:55:05.107Z","comments":true,"path":"2019/07/15/Composer笔记/","link":"","permalink":"http://blog.51ai.vip/2019/07/15/Composer笔记/","excerpt":"","text":"composer - laravel5创建laravel项目：conposer create-project laravel/laravel=5.8.* --prefer-dist ./XXX laravel=5.8.* 这里代表要部署5.8中最高版本 –prefer-dist 参数代表优先下载zip 安装vendor:composer install composer install --prefer-dist 更新：composer update composer版本更新：composer self-update 利用composer 创建laravel控制器：php artisan make:controller HomeController 会在http下 创建一Home的控制器 如果存在分目录情况，需要指定目录：php artisan make:controller Home/HomeController Laravel config:编写一些类的别名，controller中 use 简短的别名为目的。 位置：config/app 存在一数组 aliases 在里面添加 创建模型：创建一个user 的model php artisan make:model User 指定目录加入目录即可 获取项目路由：php artisan route:list composer在项目中安装三方库时候出现报错：执行命令： composer Install 返回错误： Your requirements could not be resolved to an installable set of packages. 解决： 使用 composer install --ignore-platform-reqs 命令设置忽略版本匹配然后再进行安装你所需要的composer包。","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.51ai.vip/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.51ai.vip/tags/Composer/"}]},{"title":"无版权素材站点","slug":"无版权素材站点","date":"2019-06-27T01:58:04.000Z","updated":"2020-04-14T06:55:05.123Z","comments":true,"path":"2019/06/27/无版权素材站点/","link":"","permalink":"http://blog.51ai.vip/2019/06/27/无版权素材站点/","excerpt":"","text":"最近找素材收集一些站点无版权对于我们来说可以放心使用 列表如下： http://www.pexels.com/ http://www.gratisography.com/ https://visualhunt.com/ http://finda.photo http://cupcake.nilssonlee.se/ https://www.photock.jp/ http://pngimg.com/ http://www.designerspics.com http://kaboompics.com/ https://pixabay.com/ https://visualhunt.com/ http://finda.photo http://www.freemagebank.com/ https://stocksnap.io/ http://picjumbo.com/ http://stokpic.com/ https://cn.freeimages.com/ http://www.imcreator.com/free https://www.piqsels.com/zh https://magdeleine.co/browse/ https://colorhub.me/ https://picjumbo.com/ http://streetwill.co/ https://www.foodiesfeed.com/ http://www.peakpx.com/ http://www.polayoutu.com/collections https://negativespace.co/ https://freeforcommercialuse.net/ https://mmtstock.com/","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.51ai.vip/categories/Tools/"}],"tags":[{"name":"素材","slug":"素材","permalink":"http://blog.51ai.vip/tags/素材/"}]},{"title":"Hexo笔记","slug":"Hexo笔记","date":"2019-06-04T02:46:48.000Z","updated":"2020-11-24T10:21:42.188Z","comments":true,"path":"2019/06/04/Hexo笔记/","link":"","permalink":"http://blog.51ai.vip/2019/06/04/Hexo笔记/","excerpt":"","text":"多tag文章中 多tag时,无法直接, 空格这种. 方式一: tags: [tag1,tag2] 方式二:123tags:- tag1- tag2","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.51ai.vip/categories/Hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://blog.51ai.vip/tags/hexo/"}]},{"title":"Python建立SocketSSL连接","slug":"Python建立SocketSSL连接","date":"2019-06-04T02:23:11.000Z","updated":"2020-04-14T06:55:05.116Z","comments":true,"path":"2019/06/04/Python建立SocketSSL连接/","link":"","permalink":"http://blog.51ai.vip/2019/06/04/Python建立SocketSSL连接/","excerpt":"","text":"Python Socket连接5月中旬遇到一个功能,需要利用Python建立Socket tcp连接,于设备通讯发送相关数据. 这块没接触,Python也是hello world水平. 赶紧恶补一下: Socket是网络编程的一个抽象概念。 通常我们用一个Socket表示“打开了一个网络链接”，打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型。 服务端我也不知道什么样,这里只记录客户端的相关. 这里我们得到一个文档说,需要建立socket SSL 连接,通过XML格式发送数据. 非ssl的socket:1234567import socket# 创建一个socket:s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 建立连接:s.connect(('192.168.1.230', 80)) SSL socket:端口是3344,ssl跳过验证,如果验证参数需要修改.123456789import socket s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) c = ssl.wrap_socket(s, cert_reqs=ssl.CERT_NONE) try: c.connect(('192.168.1.230', '3344'))except: return 2 这下与那台设备可以正常通讯了,后面实现具体功能就ok了.","categories":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/tags/Python/"},{"name":"Socket","slug":"Socket","permalink":"http://blog.51ai.vip/tags/Socket/"}]},{"title":"Ubutun16.04安装Python","slug":"Ubutun16-04安装Python","date":"2019-05-24T03:17:59.000Z","updated":"2020-04-14T06:55:05.117Z","comments":true,"path":"2019/05/24/Ubutun16-04安装Python/","link":"","permalink":"http://blog.51ai.vip/2019/05/24/Ubutun16-04安装Python/","excerpt":"","text":"目的安装python3.7.3安装pip 准备工作 系统内置python2.X,去除默认python的软链, sudo rm /usr/bin/python 安装一些软件包&amp;软件包保持最新状态. sudo apt-get update sudo apt-get install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 安装Python通过编译安装python 默认我下载在home里, cd 下载新python文件, wget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz 解压文件, tar zxf Python-3.7.3.tgz 把这个文件拷贝到放置的位置. 这里我放到/usr/local/python mkdir -p /usr/local/python 进入这个目录, 执行 ./configure --enable-optimizations之后执行 sudo make -j 8 这里8根据设备cpu核心数来的,不知道你可以写1(手动滑稽) make之后 该 make install 嘛? NO! 是 sudo make altinstall 装完之后, 可以尝试 python –version 看看有没有, 如果没有或者版本不对.可能是准备里你没有删除 /usr/bin/python 或者这个不存在.需要手动添加一下,我这个是没有给我创建成功. sudo ln -s /usr/local/Python-3.7.3/python /usr/bin/python 这里版本是3.7.3版本的python已经好了,但我发现没有pip.那我只好装一下pip. 安装pip同样在home目录下载:curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py 下载完成后, 执行 python get-pip.py我遇到一个问题是: Command ‘lsb_release -a’ returned non-zero exit status 1查了一下,大概意思是lsb_release上的问题,这里python2.X用到的(Ubutun自带2.X),那我解决办法是干掉他 sudo rm -f /usr/bin/lsb_release 重新执行上面的命令,ok 已经安装上pip. 到此结束.","categories":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/tags/Python/"},{"name":"Ubutun","slug":"Ubutun","permalink":"http://blog.51ai.vip/tags/Ubutun/"}]},{"title":"Go学习笔记","slug":"Go学习笔记","date":"2019-05-15T03:05:52.000Z","updated":"2020-04-14T06:55:05.109Z","comments":true,"path":"2019/05/15/Go学习笔记/","link":"","permalink":"http://blog.51ai.vip/2019/05/15/Go学习笔记/","excerpt":"","text":"变量var 声明,支持类型判断. var name string string类型 name var s string 值初始化 var age = 20 age 类型自动推断 height := 165 简短声明(仅限函数使用) i,j,k := 3.8,true,100 声明一组变量 _, res := 123,321 _特殊变量名,赋予他的值会被丢弃 常量const 声明 const Pi = 3.14 声明一个常量Pi 1234const( apple = &quot;fruit&quot; banana ) banana 常量未定义初始化值会与apple值相同 数据类型boolean,整型,浮点型,字符串,错误 布尔 bool 初始化默认fasle 整型 int8,int16,int32,int64 (有符号) uint8(byte),uint16,uint32(rune),uint64 (无符号) uintptr byte,rune 与uint8,uint32别名 整形初始化默认值0 浮点型 float32,float64(默认浮点类型) complex64,complex128 float32,float64 初始化默认值0 字符串 双引号或,UTF8编码,\\转义 初始化默认值”” 修改需要转换类型为 rune或byte 操作后再转换 数组 长度非负整数 var arr = [10]int{1,2,3,4} 声明数组 切片 slice 切片默认初始化前nil s1 := make([]int,3,5) 声明切片 append() 尾部追加元素 切片长度是包含的元素个数, 容量是能存储的元素个数. Map kV结构集合 1234m := make(map[string]int) &#123; &quot;blue&quot;: 1, &quot;red&quot;: 2&#125; `delete(m,red)` 删除map中一项 `m[&quot;orange&quot;] = 3` 增加一项 `m[&quot;blue&quot;] = 4` 更新一项 range 遍历map,slice 123for i,v := range m &#123; fmt.Println(i,v)&#125; 函数1234func sub(x,y int) (z int) &#123; z = x - y return z&#125; 声明一个方法sub,参数x,y为int型, z返回参数 int型 函数无返回值可不声明,参数也可是函数. 可以传指针或传引用操作 ...int 表示传递变长的参数 defer 关键字 在函数最后执行动作的声明(延迟代码) 局部函数声明修改不影响全局,若全局有同名变量时,内部赋值会改变全局变量(非声明). 方法方法是特殊的函数,区别于方法有前置实例接收参数(receiver) 接口一种抽象的类型 1234type I interface &#123; Get() int Put(int)&#125; 声明时,不能有字段,不能自定义方法,只声明方法,不实习现. 12345//实现接口:func f(p I) &#123; fmt.Println(p.get()) p.Out(1)&#125; 接收一个接口类型作为参数 p实现了接口I,Get(),Put()方法.","categories":[{"name":"GO","slug":"GO","permalink":"http://blog.51ai.vip/categories/GO/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://blog.51ai.vip/tags/Go/"}]},{"title":"redis笔记","slug":"redis笔记","date":"2019-04-25T09:12:52.000Z","updated":"2020-04-14T06:55:05.122Z","comments":true,"path":"2019/04/25/redis笔记/","link":"","permalink":"http://blog.51ai.vip/2019/04/25/redis笔记/","excerpt":"","text":"redis笔记单进程,默认16库, select N 切换库 flushdb 清空库 类型 string 字符串 list 列表 set 集合 sorted set有序集合 hash哈希 一个字符串支持512M 有序集合 每个元素会关联一个double类型分数。成员唯一，分数可以重复。 常用命令key：keys * exists key move key db 移除key 从库中 expire key 为key 设置过期时间 ttl key 查看多少秒过期，-1 永不过期， -2已过期 type key 查看类型 del key 删除 string：getrange key 0-N setrange key 0-N XXX 获取字符串范围内容， 设置范围内为XXX setex 设置生命值多少秒 setnx key 设置一个不存在的key mset mget msetnx list：lpush rpush lrange lpop rpop lindex llen lrem key 2 value 删除2个value ltrim key 0-N 截取并复制给key （其他的删除了） rpoplpush 弹出前面key的值 加入后面的key中 lset key index value 设置key中 index下标的值 linsert key before/afrer value1 value2 key中1值得前面后后面加入2值 set：sadd key value 添加到key集合 smembers key 查询集合 sismember key m 查询m是否在key集合中 scard key 集合ket的基数 spop key 随机移除一个元素并返回元素的值 srem key m 移除m从key的集合中 smove K1 K2 m 将k1的m一刀k2里 sinter key1 key2 交集 sunion key1 key2 并集 sdiff key1 key2 差集 hash：hset user name ali hset user age 33 设置user数据 hget user name 获取user.name hmset human name tom age 44 设置多数据 hmget human name age 获取多数据 hgetall human hdel human name 删除name hlen human 长度 hexists human age 是否存在 hkeys human 获取所有key hvals human 获取所有value hincrby hincrbyfloat hsetnx 不存在添加 zset：zadd key value：score 设置值的分数 zrange key zrangebyscore key min max （不包含 limit 升序 zrevrangebyscore 降序 zrem key value zcount key min max 范围内多少个 zscore key m 返回key 中m的分数值 zrevrange key start stop 降序展示 持久化：rdb aof rdb 快照方式定期生成临时文件，从临时文件替换上次持久化的文件。数据不是非常敏感。 dump.rdb dump.rdb 关机会清空文件，备份需要导出到另一台机器。 设备启动会去读取domp.rdb来恢复数据（文件名可以设置）。 关闭rdb 设置save为空 save命令 bgsave后台异步快照 备份到dump.rdb 优势： 适合大规模莫恢复，完整性和一致性要求不高。 劣势： 意外down 最后一次备份不到。内存被克隆一份，2倍的性能膨胀。 aof 日行形式记录每个写操作，将所有写指令记录。 appendonly yes 开启 注意flushdb all 这些东西也会记录操作。 同时存在两种备份，优先恢复aof文件，如果aof失败， 导入rbd备份数据。 aof文件损毁或异常时， 通过redis-check-aof程序修复后再恢复。 配置：appendfsync always/everysec/no 同步设置 rewrite： aof 采用文件追加方式，记录文件会越来越大，重写机智，aof 文件大小超过阈值时，会启动aof文件的内容压缩，只保留可恢复的最小指令。默认配置64M 事务： mulit 开启 语句 exec执行， discard 取消 语法错误时，全部没执行，如果设置错误，其他执行，错误的不执行。 监控 锁 乐观锁 悲观锁: 悲观锁，锁表。 乐观锁，行信息版本更新。 谁先提交谁成功。 wacth 监控字段，执行事务，如果监控字段未出现变化，事务执行成功。 复制机制： master 写 slave读 配置slave为主 slaveof 主库id 端口 info replication 查看信息 从机不能写数据 方式 1主机 多从机 主机down，从机待命。主机启动，从机继续同步主机。 从机端开，会变成master，除非配置文件规定。否则需要 slaveof 重新顶可以。 主机down后，如果从机某台执行 slaveof no one ，使当前从库变主库。 方式2 主机-&gt;从机-&gt;从机 相连 方式3 哨兵 监控主机是否down，down后根据投票选出从机转换主库。 配置中添加 sentinel.conf ，编写配置： sentinel monitor 主机配置 地址 端口 1 1标识投票 启动哨兵：redis-sentinel 哨兵配置","categories":[{"name":"Redis","slug":"Redis","permalink":"http://blog.51ai.vip/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.51ai.vip/tags/redis/"}]},{"title":"gulp笔记","slug":"gulp笔记","date":"2019-04-22T10:08:54.000Z","updated":"2020-04-14T06:55:05.119Z","comments":true,"path":"2019/04/22/gulp笔记/","link":"","permalink":"http://blog.51ai.vip/2019/04/22/gulp笔记/","excerpt":"","text":"gulpgulp.js是一个前端构建工具。 安装 npm 安装全局gulp，npm install -g gulp。（如果没有梯子，最好安装下cnpm）cnpm 安装 npm install -g cnpm --registry=https://registry.npm.taobao.org安装完cnpm，下面所有npm操作替换cnpm 执行即可。 进入项目，初始化（npm init） 项目安装gulp，项目文件夹下，npm install --save-dev gulp。 (–save-dev 加入此项目依赖中，不需要可取消这个参数) 项目根创建gulpfile.js文件，文件内创建任务测试。 1234var gulp = require(&apos;gulp&apos;);gulp.task(&apos;default&apos;,function()&#123; console.log(&apos;hello world!&apos;);&#125;); 运行 gulp，可以看到默认执行，输出 hello world! 。测试成功。 gulp API上面运行 gulp 执行default ，这个是gulp API。 [文档](https://www.gulpjs.com.cn/docs/api/) gulp工作方式gulp.src 获取文件流,通过pipe方法导入到插件，插件处理的流通过pipe方法导入 gulp.dest中, gulp.dest 输出目标文件。 gulp srcgulp.src(globs[, options]) 输出（Emits）符合所提供的匹配模式（glob）或者匹配模式的数组（array of globs）的文件。 将返回一个 Vinyl files 的 stream 它可以被 piped 到别的插件中。 文档这意思看着有点费劲，理解为获取文件路径。gulp通过这个方法获取到处理的文件流。 参数： globs 文件匹配模式，匹配文件路径，文件名。 类型： string array options 额外可选参数 类型： object 额外参数需要看手册 gulp.destgulp.dest(path[, options]) 能被 pipe 进来，并且将会写文件。并且重新输出（emits）所有数据，因此你可以将它 pipe 到多个文件夹。如果某文件夹不存在，将会自动创建它。 理解为写文件，写入path路径文件。 参数： path 文件写入路径 类型：string function options 额外可选参数 类型：object gulp.taskgulp.task(name[, deps], fn) 定义一个使用 Orchestrator 实现的任务（task）。 用来定义任务，内部使用的是Orchestrator。 参数： name 任务名字 deps 是当前任务需要的其他任务，一个数组。依赖任务，先于此任务执行。 类型：array fn 该函数定义任务所要执行的一些操作，把任务要执行的代码写在里面。 gulp.watchgulp.watch(glob[, opts], tasks)gulp.watch(glob[, opts, cb]) 监视文件，并且可以在文件发生改动时候做一些事情。 参数： glob 文件匹配模式 类型 string array opts 可选配置 类型 object tasks 文件变动后执行的任务 类型 array cb 一个函数，文件发生变化时调用的函数。 类型 function Glob 匹配模式 (node-glob）参考语法 123456789101112131415161718192021222324252627282930匹配符 说明 * 匹配文件路径中的0个或多个字符，但不会匹配路径分割符， 除非分隔符出现在末尾 ** 匹配路径的0个会多个目录 及子目录 需要单独出现， 即他左右不能有其他的东西了如果出现在末尾，也能匹配文件 ？ 匹配文件路径中的一个字符（不能匹配路径分割符/） [...] 匹配方括号中 出现字符的任意一个，当方括号中第一个字符为^或!时， 则表示不匹配方括号中出现字符中的任意一个， 类似于js中正则表达式中的用法 !(pattern|pattern|pattern) 匹配任何与括号中给定的任意模式都不匹配 ？(pattern|pattern|pattern) 匹配括号中给定的任意模式0次或1次 +(pattern|pattern|pattern) 匹配括号中的至少一次 *(pattern|pattern|pattern) 匹配括号中给定的任意模式0次或多次 @(pattern|pattern|pattern) 匹配括号中 给定的任意模式一次 eg：glob 匹配 |能匹配 a.js,x.y,abc,abc/,但不能匹配a/b.js| |.* a.js,style.css,a.b,x.y //*.js 能匹配 a/b/c.js,x/y/z.js,不能匹配a/b.js,a/b/c/d.js ** 能匹配 abc,a/b.js,a/b/c.js,x/y/z,x/y/z/a.b,能用来匹配所有的目录和文件 a/**/z 能匹配 a/z,a/b/z,a/b/c/z,a/d/g/h/j/k/z a/**b/z 能匹配 a/b/z,a/sb/z,但不能匹配a/x/sb/z,因为只有单**单独出现才能匹配多级目录 ?.js 能匹配 a.js,b.js,c.js a?? 能匹配 a.b,abc,但不能匹配ab/,因为它不会匹配路径分隔符 [xyz].js 只能匹配 x.js,y.js,z.js,不会匹配xy.js,xyz.js等,整个中括号只代表一个字符 [^xyz].js 能匹配 a.js,b.js,c.js等,不能匹配x.js,y.js,z.js 多种匹配模式时，使用数组gulp.src([&#39;js/*.js&#39;,&#39;css/*.css&#39;,&#39;*.html&#39;]) 数组中可以用 ！ 排除(放在数组第一个无效)gulp.src([*.js,&#39;!b*.js&#39;]) 编写一个任务常用到压缩，写个压缩demo。目录，根目录下有两个文件夹，dist空文件，src目录,src/js文件夹2个文件，common.js,demo.js。任务目标，将js目录下的.js文件，压缩合并为new.min.js。之后将合并压缩的文件保存到dist/js/。 我们在初始化后的项目中，先安装所需插件，gulp-rename（重命名插件）,gulp-uglify（压缩js插件），gulp-concat（合并文件插件）。npm install gulp-rename gulp-uglify gulp-concat –save-dev 编辑gulpfile.js 123456789101112var gulp=require(&apos;gulp&apos;); var rename= require(&apos;gulp-rename&apos;); //引入插件var uglify= require(&apos;gulp-uglify&apos;);var concat= require(&apos;gulp-concat&apos;); gulp.task(&apos;js&apos;, function()&#123; //创建名为 js的任务 return gulp.src(&apos;src/js/*.js&apos;) //读取文件流 .pipe(concat()) //合并 .pipe(uglify()) //压缩 .pipe(rename(&#123;suffix: &apos;.min&apos;&#125;)) //重命名 .pipe(gulp.dest(&apos;dist/js/&apos;)) //输出到指定路径 &#125;); 文件保存后，命令行执行任务： gulp js 。可以看到Finshed时间，去dist目录可以看到合并压缩的文件已在里面。 gulp插件 CSS压缩 gulp-minify-css Js压缩 gulp-uglify 重命名 gulp-rename 文件合并 gulp-concat 自动加载 gulp-load-plugins less编译 gulp-less sass编译 gulp-sass","categories":[{"name":"前端","slug":"前端","permalink":"http://blog.51ai.vip/categories/前端/"}],"tags":[{"name":"gulp","slug":"gulp","permalink":"http://blog.51ai.vip/tags/gulp/"}]},{"title":"Centos7时间设置","slug":"Centos7时间设置","date":"2019-04-19T03:42:02.000Z","updated":"2020-04-14T06:55:05.107Z","comments":true,"path":"2019/04/19/Centos7时间设置/","link":"","permalink":"http://blog.51ai.vip/2019/04/19/Centos7时间设置/","excerpt":"","text":"Centos7时间相关查看时间datehwclock 硬件时间timedatectl 各时间状态 设置&amp;更新服务时间安装ntpdateyum install utp ntpdate 设置同步ntpdate cn.pool.ntp.org (time.windows.com) 地址看喜好 设置硬件时间hwclock –systohc 设置时区timedatectl set-timezone Asia/Shanghai （上海） timedatectl 很多设置，需要请查相关资料。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos7","slug":"Centos7","permalink":"http://blog.51ai.vip/tags/Centos7/"}]},{"title":"Centos7防火墙相关设置","slug":"Centos7防火墙相关设置","date":"2019-04-18T09:44:22.000Z","updated":"2020-04-14T06:55:05.107Z","comments":true,"path":"2019/04/18/Centos7防火墙相关设置/","link":"","permalink":"http://blog.51ai.vip/2019/04/18/Centos7防火墙相关设置/","excerpt":"","text":"Centos7与之前不太一样以前都是用iptables，公司服务器环境事7，凑巧不熟一台新服务。我为了测试，再本地虚机上装了一台。这里默认防火墙是 firewall，其实为了省事还是可以安装一个iptables的。这里学习一下firewall一些操作。 查看防火墙服务状态systemctl status firewalld ####查看f防火墙状态firewall-cmd --state 查看规则firewall-cmd --list-all ####停止&amp;开启防&amp;重启火墙systemctl stop firewalld.servicesystemctl start firewalld.servicesystemctl restart firewalld.service 关闭防火墙systemctl disable firewalld.service 重载防火墙firewall-cmd —reload 查询开放端口firewall-cmd --list-ports 开放一个端口 例如tcp 8010firewall-cmd –zone=public –add-port=80/tcp –permanent –zone #作用域–add-port=8010/tcp #添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 查询某端口是否开放(8010)firewall-cmd --query-port=8010/tcp 移除端口规则firewall-cmd --permanent --remove-port=8010/tcp","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos7","slug":"Centos7","permalink":"http://blog.51ai.vip/tags/Centos7/"}]},{"title":"Centos7启动等级设置","slug":"Centos7启动等级设置","date":"2019-04-15T08:55:19.000Z","updated":"2020-04-14T06:55:05.106Z","comments":true,"path":"2019/04/15/Centos7启动等级设置/","link":"","permalink":"http://blog.51ai.vip/2019/04/15/Centos7启动等级设置/","excerpt":"","text":"Centos7启动级别启动级别分为7个：0 - 系统停机状态1 - 单用户工作状态2 - 多用户状态（没有NFS）3 - 多用户状态（有NFS）4 - 系统未使用，留给用户5 - 图形界面6 - 系统正常关闭并重新启动 切换启动级别之前一直都是在种端中输入指令 init3 切换启动级别。设置永久启动3级别， vi /etc/inittab 把init3设置默认即可。 centos7 设置出现不同runlevels被targets所取代，即CentOS7采用加载target的方式来替代之前的启动级别。multi-user.target = init3graphical.target = init5我们日常实用图形窗口init5，我们不需要图形，可以切换到init3等启动级别上。systemctl set-default multi-user.target 设置为init3systemctl set-default graphical.target 设置为init5","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos7","slug":"Centos7","permalink":"http://blog.51ai.vip/tags/Centos7/"}]},{"title":"Docker常用命令","slug":"Docker常用命令","date":"2019-04-11T07:09:19.000Z","updated":"2020-11-24T10:08:10.947Z","comments":true,"path":"2019/04/11/Docker常用命令/","link":"","permalink":"http://blog.51ai.vip/2019/04/11/Docker常用命令/","excerpt":"","text":"Docker常用命令说常用不如说自己用到的命令。 容器相关学习了一下docker，基础常用命令记录下。 ####docker run/新建并启动容器这个run其实包含两个不走，先执行新建容器(docker create),接着启动容器(docker start)。敲两个是不是有点麻烦吧。 docker run xx [COMMAND] 例子 docker run -it ubuntu:14.04 /bin/bash 这里希望启动一个基于 ubuntu 14.04镜像 来创建一个容器，-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上，-i则让容器的标准输入保持打开。更多的命令选项可以通过man docker-run命令来查看。之后命令还有一项，启动一个bash终端。 这条命令涉及到很多知识了。-参数 常用 -i -d -t -p， -d 是否在后台运行，-p 映射到本地主机端口。剩下的看手册来补下。 docker create &amp;&amp; docker start &amp;&amp; docker stop创建，启动，停止。有一个容易停止了，可以用 docker start XX容器 启动。 XX 可以是容器的ID，也可以是name。 docker rm删除一个容器（最好先把这个容器停止了再删除）。-f 可以强制删除。-v 删除与容器关联的卷（如果刚学习还真不知道什么是卷）。 docker attach进入容器，如果开启了一个 -d 后台启动容器。 我们怎么进去看看？ docker attach XX容器这个命令我学习时候用过，感觉有时候不太好使。命令执行完卡那不动。 docker exec可以在容器内直接执行任意命令。docker exec -it xx /bin/bash 这可以进入xx镜像，并打开bash。 相比这个比上面的attach 好多了。 docker ps列出启动中的容器， docker ps -a 列出所有镜像。 ###仓库相关 docker images列出本地镜像文件 docker rmi删除本地镜像文件 docker seach xxx在docker hub查询xxx 镜像 docker pull像不像git？ docker pull xx 可以下载xx镜像到本地。 （还能联想到 push 吧？ commit ？ 这些吧） docker login登陆docker hub docker push推送本地镜像到docker hub上。 数据相关-v在容器内创建数据卷 docker run -d -v /test ubuntu 在此镜像下创建一个test数据卷也可以挂在主机目录为数据卷 docker run -d -v /usr/local/src:/opt/test ubuntu 将本地的/usr/lcoal/src 挂载到此镜象的 /opt/test 作为数据卷。 在本机修改，容器内可以看到。这里可以增加参数来控制读写，默认读写。 volumes-from数据卷容器容器与容器间的数据挂在参数。例如有个容器为 files ，通过另一个 test来挂在files。 docker run -it --volumes-from files --name test ubuntu--name 是为后者容器起名。这个名字叫test 挂在了files 容器的数据。 端口映射，容器互联-p &amp;&amp; -Pdocker run -itd -p 8080:80 --name web nginx:1.15 本机8080端口映射到容器80.-p 需要自己分配端口 -P Docker会随机映射一个49000~49900的端口 docker port查看映射端口配置 link--link参数可以让容器之间安全地进行交互 基本上了解到的命令吧，后续根据搭建环境以及使用中来丰富其他的命令和参数。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/tags/Docker/"}]},{"title":"Ubutun下安装Docker","slug":"Ubutun下安装Docker","date":"2019-04-04T06:57:16.000Z","updated":"2020-04-14T06:55:05.117Z","comments":true,"path":"2019/04/04/Ubutun下安装Docker/","link":"","permalink":"http://blog.51ai.vip/2019/04/04/Ubutun下安装Docker/","excerpt":"","text":"Docker简介 一个能够把开发的应用程序自动部署到容器的开源引擎三大概念：镜像（Image）容器（Container）仓库（Repository） 具体信息请参考官方。官方概述（养成看文档习惯） 安装环境Ubuntu 16.04 LTS Docker安装根据官方doc安装。官方doc1.如果你之前装过，命令卸载。sudo apt-get remove docker docker-engine docker.io containerd runc 2.更新包索引apt-get update 3.安装包以允许apt通过HTTPS使用存储库:sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common（斜线换行，一条命令） 4.添加Docker的官方GPG密钥:curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo apt-key fingerprint 0EBFCD88 5.使用以下命令设置稳定存储库。要添加 夜间或测试存储库，请在下面的命令中的单词后添加单词nightly或test（或两者）stable。$ sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; (lsb_release -cs子命令返回Ubuntu发行版的名称) 6.安装最新版本的Docker CE和containerd，或者转到下一步安装特定版本： sudo apt-get install docker-ce docker-ce-cli containerd.io 7.运行hello-world 映像验证是否正确安装了Docker CE: sudo docker run hello-world (执行之后，返回docker的信息) 至此，安装过程是结束了。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/tags/Docker/"},{"name":"Ubutun","slug":"Ubutun","permalink":"http://blog.51ai.vip/tags/Ubutun/"}]},{"title":"Hexo博客安装与配置","slug":"hexo博客安装与配置","date":"2019-04-01T09:59:31.000Z","updated":"2020-09-15T01:23:18.233Z","comments":true,"path":"2019/04/01/hexo博客安装与配置/","link":"","permalink":"http://blog.51ai.vip/2019/04/01/hexo博客安装与配置/","excerpt":"","text":"wordpress 之后wordpress 使用很方便，但是折腾几次之后。由于一次意外，导致管理者把我的vps被停掉。虽然有些文章还是保留了。但是这次之后感觉自己还是找一个稳妥的家。连接hexo搭建的博客之后，打算自己来折腾一下。 记录笔记环境在windows上写笔记，环境目前是windows下操作。linux，mac系统中需要注意一些细节吧。存在提不到情况，先做好出现问题考虑自行排查。 准备看下hexo的安装提示。 hexo 需要Node.js 和 Git 。 安装 Node.js官网: 官网widows，mac，linux 都有对应的安装方法。根据自己的环境来安装。 安装 Git官网: 官网根据自己环境安装。 安装Hexo通过npm来安装 Hexo。命令: npm install -g hexo-cli什么鬼，通过这个命令发现没有实现正常安装。理由，我们在天朝。解决方式： 替换国内npm源。命令: npm install -g cnpm --registry=https://registry.npm.taobao.org请注意不同系统在操作此命令时，需要一些设置。linux 如果使用下面命令需要自建软链。 cnpm ln -s /yourdir/bin/cnpm /usr/local/npm下一步用cnpm 来安装 Hexo： cnpm install hexo-cli -g验证hexo 是否安装： hexo v 会列出版本信息。 下面使用Hexo来创建blog： 创建项目文件夹。这里开始通过git bash来使用命令行操作。 进入项目文件夹，初始化。 hexo init （这里也可以，通过 hexo init 你的项目文件夹名 结果一样）这里会看到目录有相关文件了。具体这些文件，看下 手册 是什么意思。这时候其实已经是一个博客站点了。 命令 hexo g , hexo s 得到信息：Hexo is running at http：//lcoalhost:4000` 注意4000端口需要未被占用。 访问地址就可以看到初始化的站点了。 （不喜欢默认主题可以修改主题） 写文章写文章需要先创建文档，这个文档默认生成在_post 文件夹下。 命令 hexo new testdoc 得到信息： Created:···path/testdoc.md 文档的位置，需要编辑这个文档来写文章（Markdown文档）。文档写好保存之后。命令 hexo g , hexo s 之后我们访问之 localhost:4000 就能看到自己的新文章了。 推送到Git仓库，在线访问。首先需要一个 GitHub ，注册账号。创建一个与账户名一样的库， 用户名.github.io , 之后在项目文件夹中，编辑 _config.yml 配置文件。 1234deploy: type: git repo: https://github.com/用户名/用户名.github.io.git (我相信你能知道这个地址在哪里) branch: master 之前写过testdoc.md 这个文件。提交到git库上，命令： hexo d , 提交是，会弹出账号密码让你输入。接着得到提示： Deploy done: git。 这里我们就提交到库上了。 （账号密码提交比较麻烦，可以通过配置公钥来解决）这里如果出现错误 Deployer not found：git ，需要安装一下。 命令 npm install hexo-deployer-git --save这时候我们可以通过 用户名.github.io.git 这个地址访问到博客了。（不喜欢这个地址，可以通过域名来绑定） 主题更换默认的主题让我们觉得太不个性化了。还没有能力自己操刀编辑，怎么办？ 建议先看下文档.了解一下,培养看文档习惯. 可以使用别人的主题，官网提供 提供一些，也可以通过网上其他人的推荐来使用自己喜欢的主题。例如在官网地址上看到有一个名字是 Next(很多人有这个,或基于此主题修改). 点击可以语言并且访问.地址 , 我们需要克隆到自己项目下 themes 文件下. 你可以下载zip到自己项目下解压,不过有些麻烦也不够B格.我们使用git操作. 打开gitbash, 进入到自己项目下/themes 命令 git clone https://github.com/theme-next/hexo-theme-next.git . 执行完后,themes 下会有这个文件. 使用next 主题, 需要在 _config.yml 上面设置主题. theme: next 配置主题为next 之后通过命令 hexo g, hexo s. 两个命令后, 登陆localshot:4000 查看一下. 嗯,已经替换成功了. 目前只是替换了主题,主题也是需要配置的,我们需要在 _config.yml 配置菜单等一些参数. 主题相关修改参数配置是需要在 项目/themes/languages/{language}.yml具体配置希望你看下每个主题的README,或者文档来学习着自己修改. 还要涉及到页面的问题,我们之前 hexo new xx文章 ,都是默认_post文件夹下, 如果我们要定义归档,友链,等页面.也是通过new 命令来实现的. 例如: 建立 tags页面 hexo new page tags之后你会看到 项目下/source/ 会出现tags 文件夹,进入里面会有一个index.md .这个文件就是你需要的tags 页面. 域名我们觉得github 这个url不太喜欢,并且也很长.可以配置自己的域名.首先我们需要一个自己的域名,通过万网什么的来购买一个.我是通过阿里云上万网购买的一个域名.这里不详细来说明域名的购买. 万网控制台里面,有域名的功能(例如阿里云,登陆后,控制台-&gt;域名-&gt;点击域名-&gt;域名解析). 在github，xxx.github.io 点击 settingsCustom domain 这里填写你的域名，save。 此处注意：你配置完后，会看到库中存在一个文件，CNANE文件。如果你再次提交新文档，会发现你的配置域名无法访问了！原因：你本地文件没有这个CNAME，通过hexo d 方式 更新库文件后，CNAME没了。通过配置域名后，把这个文件下载到本地项目中，位置请注意：项目/source 下。不然hexo d 不会提交到库中。 如果不搞定这个，那你每次hexo d 之后，都要改一次custom domain。（我想谁也不会每次都这么操作）到这里基本上你这台电脑上，发布你的博客。更新，推送到github都没有问题。还有一个问题就是那么如果我换一台电脑怎么办？ 通过分支来完善博客工作中使用版本控制器，很方便管理项目代码和文件。那么我们这个hexo 博客也需要这种方式来吧本地的hexo 博客项目推送到线上。如果过本地电脑出故障，或者更换电脑等情况下。我们依然可以通过clone到本地，进行发布博客。 克隆博客gitbash clone一份自己的博客(省略命令), 删除克隆后出.git 这个文件外其他文件。把之前本地初始化项目中的文件都复制到此项目中。 新建分支 git branch hexo, git checkout hexo. 两条命令,新建分支,切换至hexo 分支. 在新分支中，提交我们刚才复制过来的文件。 git add --all 提交文件并push到远程。 git commit -m &quot;mybolg files&quot;, git push origin hexo 推送带云端。 这下完成了，不用担心换电脑。换电脑后，clone一下，继续可以发布。ps：git你需要自己装。之后我们一直再这个 hexo 分支就好啦。每次hexo d 之后记得把新文件提交到hexo分支。 add commit push 三步骤不能忘。 配置公钥之前没提到这个，是因为我怕忘记密码，每次都手输入密码。也不是每个人都喜欢我这么操作。那可以选择配置公钥来解决提交时的认证。 gitbash ssh-keygen 生成密钥，注意看信息密钥提示位置。 打开生成目录下的 id_res.pub 这个是公钥。打开复制里面的数据，复制。 需要粘贴到github settings-&gt;SSH and GPG keys 里面。 测试一下配置 gitbash ssh -T git@github.com 得到信息 You’ve successfully authenticated, but GitHub does not provide shell access. 配置正常。 改完这里还不可以，需要配置项目hexo配置文件了，还记得是哪个文件嘛？（ _config.yml）之前我们用的是https，现在我们需要用ssh地址提交了。4.修改 _config.yml 这段配置的 repo地址，看下之前参数和现在参数。 12345deploy: type: git #repo: https://github.com/chenweil/chenweil.github.io.git # https repo: git@github.com:chenweil/chenweil.github.io.git # ssh branch: master 到这里我们已经配置好，我们下次写完文章是 hexo d 不会让你输入密码了。真的不用输入密码了吗? 你可能会遇到问题,怎么还需要认证?(因为我这环境出现了问题)看下错误 :git push origin hexofatal: HttpRequestException encountered.如果你现者句话,那么需要你更新一下Windows的git凭证管理器.管理器地址 到此基本的配置已经完成，文中只是简单的描述了基础工作。再哪方面出现问题需要通过文档和网络来查询问题。第一次接触此框架，还是好好看文档。你通过网络查询的很多结果存在一些问题。例如版本不同，环境不同等。最好的方法还是自己来分析，处理。养成好习惯，戒心浮气躁，坚持自己来解决问题。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.51ai.vip/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.51ai.vip/tags/Hexo/"}]}]}